{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"FinalData/channel_last_data.npz\")\n",
    "normalData = data[\"input\"]\n",
    "shuffledData = data[\"input\"]\n",
    "np.random.shuffle(shuffledData)\n",
    "\n",
    "trainInput,trainOutput = shuffledData[0:15000],shuffledData[0:15000]\n",
    "testInput,testOutput = shuffledData[15000:],shuffledData[15000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/jupyter/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Sokoban\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "def normal_loss(y_true, y_pred):\n",
    "    return K.mean(categorical_crossentropy(y_true, y_pred), axis=[1,2])\n",
    "\n",
    "def numpyToString(array):\n",
    "    gameCharacters=\"# @$.+*\"\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(gameCharacters))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(gameCharacters))\n",
    "    intArray = np.argmax(array, axis=2)\n",
    "    output=\"\"\n",
    "    for (i,j), index in np.ndenumerate(intArray):\n",
    "        if i > 0 and j == 0:\n",
    "            output += \"\\n\"\n",
    "        output += int_to_char[index]\n",
    "    return output\n",
    "\n",
    "def convertStringTo2DArray(string):\n",
    "    return np.array([list(l) for l in string.split(\"\\n\")])\n",
    "\n",
    "def getOneHotEncodingMap(data):\n",
    "    gameCharacters=\"# @$.+*\"\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(gameCharacters))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(gameCharacters))\n",
    "\n",
    "    encodingData = np.zeros((data.shape[0], data.shape[1], len(gameCharacters)))\n",
    "    for (i,j),c in np.ndenumerate(data):\n",
    "        index=char_to_int[c]\n",
    "        encodingData[i][j][index]=1\n",
    "    return encodingData\n",
    "\n",
    "def getHammingDistance(data1, data2):\n",
    "    data1=np.argmax(data1, axis=3)\n",
    "    data2=np.argmax(data2, axis=3)\n",
    "    result=np.absolute(data1-data2)\n",
    "    result=np.clip(result,0,1)\n",
    "    return np.sum(result)/data1.shape[0]\n",
    "\n",
    "def combineTwoStrings(str1, str2):\n",
    "    if len(str1) == 0:\n",
    "        return str2\n",
    "    if len(str2) == 0:\n",
    "        return str1\n",
    "    lines1=str1.split(\"\\n\")\n",
    "    lines2=str2.split(\"\\n\")\n",
    "    linesOut=[]\n",
    "    for i in range(10):\n",
    "        linesOut.append(lines1[i] + \"  \" + lines2[i])\n",
    "    return \"\\n\".join(linesOut)\n",
    "\n",
    "def getNoisedState(numpyLevel, randomSize=20):\n",
    "    stringLvl=numpyToString(numpyLevel)\n",
    "    state=Sokoban.State()\n",
    "    state.stringInitialize(stringLvl.split(\"\\n\"))\n",
    "    for i in range(randomSize):\n",
    "        if random.random() < 0.5:\n",
    "            state.update(0, 2*random.randint(0,1) - 1)\n",
    "        else:\n",
    "            state.update(2*random.randint(0,1) - 1, 0)\n",
    "    return getOneHotEncodingMap(convertStringTo2DArray(str(state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Different Encoding Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10, 10, 7)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 12, 12, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 12, 12, 128)       8192      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1, 1, 32)          1056      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1, 1, 32)          1056      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 10, 10, 7)         8071      \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          (None, 10, 10, 7)         0         \n",
      "=================================================================\n",
      "Total params: 202,983\n",
      "Trainable params: 202,983\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 2584 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 3s 191us/step - loss: 0.5891 - val_loss: 0.4122\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.3945 - val_loss: 0.3879\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3641 - val_loss: 0.3468\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.3333 - val_loss: 0.3321\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.3182 - val_loss: 0.3180\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.3097 - val_loss: 0.3120\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.3028 - val_loss: 0.3071\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2952 - val_loss: 0.2939\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2869 - val_loss: 0.2913\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2867 - val_loss: 0.2870\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2805 - val_loss: 0.2836\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2738 - val_loss: 0.2766\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2687 - val_loss: 0.2763\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2622 - val_loss: 0.2721\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2588 - val_loss: 0.2650\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2551 - val_loss: 0.2601\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2520 - val_loss: 0.2607\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2526 - val_loss: 0.2580\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2469 - val_loss: 0.2549\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2440 - val_loss: 0.2533\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2424 - val_loss: 0.2594\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2418 - val_loss: 0.2486\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2393 - val_loss: 0.2503\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2401 - val_loss: 0.2533\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2368 - val_loss: 0.2506\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2348 - val_loss: 0.2497\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2348 - val_loss: 0.2457\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2313 - val_loss: 0.2422\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2292 - val_loss: 0.2473\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2273 - val_loss: 0.2371\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2270 - val_loss: 0.2363\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2226 - val_loss: 0.2377\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 1s 65us/step - loss: 0.2204 - val_loss: 0.2332\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2194 - val_loss: 0.2425\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2197 - val_loss: 0.2377\n",
      "Epoch 36/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2185 - val_loss: 0.2303\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2152 - val_loss: 0.2306\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2150 - val_loss: 0.2430\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2141 - val_loss: 0.2309\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2125 - val_loss: 0.2258\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2109 - val_loss: 0.2348\n",
      "Epoch 42/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2110 - val_loss: 0.2332\n",
      "Epoch 43/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2087 - val_loss: 0.2283\n",
      "Epoch 44/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2080 - val_loss: 0.2272\n",
      "Epoch 45/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2074 - val_loss: 0.2222\n",
      "Epoch 46/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2062 - val_loss: 0.2251\n",
      "Epoch 47/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2053 - val_loss: 0.2313\n",
      "Epoch 48/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.2032 - val_loss: 0.2249\n",
      "Epoch 49/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2029 - val_loss: 0.2260\n",
      "Epoch 50/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2007 - val_loss: 0.2190\n",
      "Epoch 51/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1991 - val_loss: 0.2168\n",
      "Epoch 52/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1979 - val_loss: 0.2169\n",
      "Epoch 53/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1954 - val_loss: 0.2140\n",
      "Epoch 54/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1948 - val_loss: 0.2187\n",
      "Epoch 55/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1931 - val_loss: 0.2141\n",
      "Epoch 56/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1914 - val_loss: 0.2136\n",
      "Epoch 57/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1924 - val_loss: 0.2089\n",
      "Epoch 58/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1911 - val_loss: 0.2172\n",
      "Epoch 59/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1895 - val_loss: 0.2077\n",
      "Epoch 60/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1868 - val_loss: 0.2136\n",
      "Epoch 61/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1868 - val_loss: 0.2090\n",
      "Epoch 62/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1846 - val_loss: 0.2048\n",
      "Epoch 63/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1876 - val_loss: 0.2040\n",
      "Epoch 64/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1825 - val_loss: 0.2101\n",
      "Epoch 65/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1814 - val_loss: 0.2064\n",
      "Epoch 66/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1809 - val_loss: 0.2027\n",
      "Epoch 67/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1800 - val_loss: 0.2015\n",
      "Epoch 68/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1783 - val_loss: 0.2007\n",
      "Epoch 69/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1780 - val_loss: 0.1999\n",
      "Epoch 70/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1768 - val_loss: 0.2053\n",
      "Epoch 71/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1754 - val_loss: 0.2036\n",
      "Epoch 72/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1747 - val_loss: 0.2001\n",
      "Epoch 73/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1732 - val_loss: 0.2021\n",
      "Epoch 74/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1731 - val_loss: 0.2019\n",
      "Epoch 75/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1742 - val_loss: 0.2004\n",
      "Epoch 76/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1717 - val_loss: 0.1991\n",
      "Epoch 77/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1710 - val_loss: 0.2001\n",
      "Epoch 78/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1696 - val_loss: 0.1980\n",
      "Epoch 79/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1692 - val_loss: 0.1972\n",
      "Epoch 80/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1679 - val_loss: 0.1926\n",
      "Epoch 81/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1738 - val_loss: 0.1940\n",
      "Epoch 82/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1654 - val_loss: 0.1958\n",
      "Epoch 83/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1661 - val_loss: 0.1958\n",
      "Epoch 84/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1648 - val_loss: 0.1989\n",
      "Epoch 85/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1636 - val_loss: 0.1970\n",
      "Epoch 86/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1638 - val_loss: 0.1896\n",
      "Epoch 87/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1644 - val_loss: 0.2098\n",
      "Epoch 88/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1642 - val_loss: 0.1937\n",
      "Epoch 89/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1623 - val_loss: 0.1888\n",
      "Epoch 90/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1599 - val_loss: 0.1899\n",
      "Epoch 91/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1614 - val_loss: 0.2082\n",
      "Epoch 92/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1670 - val_loss: 0.1892\n",
      "Epoch 93/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1575 - val_loss: 0.1932\n",
      "Epoch 94/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1578 - val_loss: 0.1963\n",
      "Epoch 95/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1579 - val_loss: 0.1952\n",
      "Epoch 96/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1578 - val_loss: 0.2008\n",
      "Epoch 97/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1590 - val_loss: 0.1875\n",
      "Epoch 98/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1547 - val_loss: 0.1960\n",
      "Epoch 99/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1562 - val_loss: 0.1940\n",
      "Epoch 100/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1554 - val_loss: 0.1936\n",
      "Epoch 101/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1554 - val_loss: 0.1899\n",
      "Epoch 102/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1832 - val_loss: 0.1864\n",
      "Epoch 103/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1526 - val_loss: 0.1865\n",
      "Epoch 104/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1515 - val_loss: 0.1868\n",
      "Epoch 105/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1514 - val_loss: 0.1943\n",
      "Epoch 106/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1515 - val_loss: 0.1849\n",
      "Epoch 107/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1500 - val_loss: 0.1873\n",
      "Epoch 108/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1554 - val_loss: 0.2117\n",
      "Epoch 109/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1518 - val_loss: 0.1857\n",
      "Epoch 110/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1492 - val_loss: 0.1907\n",
      "Epoch 111/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1490 - val_loss: 0.1898\n",
      "Epoch 112/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1485 - val_loss: 0.1843\n",
      "Epoch 113/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1482 - val_loss: 0.1932\n",
      "Epoch 114/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1479 - val_loss: 0.1856\n",
      "Epoch 115/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1466 - val_loss: 0.1936\n",
      "Epoch 116/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1486 - val_loss: 0.1927\n",
      "Epoch 117/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1484 - val_loss: 0.1859\n",
      "Epoch 118/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.1475 - val_loss: 0.1833\n",
      "Epoch 119/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1453 - val_loss: 0.1850\n",
      "Epoch 120/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1452 - val_loss: 0.1836\n",
      "Epoch 121/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1477 - val_loss: 0.1948\n",
      "Epoch 122/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1437 - val_loss: 0.1859\n",
      "Epoch 123/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1449 - val_loss: 0.1828\n",
      "Epoch 124/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1446 - val_loss: 0.1860\n",
      "Epoch 125/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1421 - val_loss: 0.1872\n",
      "Epoch 126/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1486 - val_loss: 0.1856\n",
      "Epoch 127/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1418 - val_loss: 0.1866\n",
      "Epoch 128/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1414 - val_loss: 0.1830\n",
      "Epoch 129/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1392 - val_loss: 0.1841\n",
      "Epoch 130/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1559 - val_loss: 0.2275\n",
      "Epoch 131/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1480 - val_loss: 0.1814\n",
      "Epoch 132/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1374 - val_loss: 0.1812\n",
      "Epoch 133/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1372 - val_loss: 0.1804\n",
      "Epoch 134/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1378 - val_loss: 0.1919\n",
      "Epoch 135/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1374 - val_loss: 0.1807\n",
      "Epoch 136/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1393 - val_loss: 0.1825\n",
      "Epoch 137/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1376 - val_loss: 0.1822\n",
      "Epoch 138/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1363 - val_loss: 0.1840\n",
      "Epoch 139/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1370 - val_loss: 0.1912\n",
      "Epoch 140/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1386 - val_loss: 0.1832\n",
      "Epoch 141/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1349 - val_loss: 0.1912\n",
      "Epoch 142/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1361 - val_loss: 0.1842\n",
      "Epoch 143/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1359 - val_loss: 0.1887\n",
      "Epoch 144/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1416 - val_loss: 0.2026\n",
      "Epoch 145/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1355 - val_loss: 0.1801\n",
      "Epoch 146/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1350 - val_loss: 0.1808\n",
      "Epoch 147/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1329 - val_loss: 0.1974\n",
      "Epoch 148/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1408 - val_loss: 0.1853\n",
      "Epoch 149/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1321 - val_loss: 0.1846\n",
      "Epoch 150/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1323 - val_loss: 0.1821\n",
      "Epoch 151/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1316 - val_loss: 0.1812\n",
      "Epoch 152/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1343 - val_loss: 0.1901\n",
      "Epoch 153/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1336 - val_loss: 0.1842\n",
      "Epoch 154/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1333 - val_loss: 0.1874\n",
      "Epoch 155/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1312 - val_loss: 0.1833\n",
      "Epoch 156/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1301 - val_loss: 0.1830\n",
      "Epoch 157/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1305 - val_loss: 0.1792\n",
      "Epoch 158/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1304 - val_loss: 0.1886\n",
      "Epoch 159/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1332 - val_loss: 0.1915\n",
      "Epoch 160/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1326 - val_loss: 0.1818\n",
      "Epoch 161/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1299 - val_loss: 0.1829\n",
      "Epoch 162/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1293 - val_loss: 0.1813\n",
      "Epoch 163/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1282 - val_loss: 0.1873\n",
      "Epoch 164/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1283 - val_loss: 0.1843\n",
      "Epoch 165/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1294 - val_loss: 0.1952\n",
      "Epoch 166/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1301 - val_loss: 0.1827\n",
      "Epoch 167/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1273 - val_loss: 0.1845\n",
      "Epoch 168/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1279 - val_loss: 0.1894\n",
      "Epoch 169/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1300 - val_loss: 0.1819\n",
      "Epoch 170/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1266 - val_loss: 0.1805\n",
      "Epoch 171/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1290 - val_loss: 0.2300\n",
      "Epoch 172/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1348 - val_loss: 0.1845\n",
      "Epoch 173/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1260 - val_loss: 0.1846\n",
      "Epoch 174/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1257 - val_loss: 0.1825\n",
      "Epoch 175/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1241 - val_loss: 0.1830\n",
      "Epoch 176/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1245 - val_loss: 0.1858\n",
      "Epoch 177/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1256 - val_loss: 0.1830\n",
      "Epoch 178/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1282 - val_loss: 0.1820\n",
      "Epoch 179/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1244 - val_loss: 0.1821\n",
      "Epoch 180/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1253 - val_loss: 0.1849\n",
      "Epoch 181/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1255 - val_loss: 0.2078\n",
      "Epoch 182/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1272 - val_loss: 0.1827\n",
      "Epoch 183/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1225 - val_loss: 0.1836\n",
      "Epoch 184/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1228 - val_loss: 0.1874\n",
      "Epoch 185/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1348 - val_loss: 0.1814\n",
      "Epoch 186/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1216 - val_loss: 0.1850\n",
      "Epoch 187/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1222 - val_loss: 0.1887\n",
      "Epoch 188/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1230 - val_loss: 0.1947\n",
      "Epoch 189/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1243 - val_loss: 0.1868\n",
      "Epoch 190/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1227 - val_loss: 0.1998\n",
      "Epoch 191/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1231 - val_loss: 0.1861\n",
      "Epoch 192/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1209 - val_loss: 0.1853\n",
      "Epoch 193/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1219 - val_loss: 0.1855\n",
      "Epoch 194/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1225 - val_loss: 0.1880\n",
      "Epoch 195/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1208 - val_loss: 0.1865\n",
      "Epoch 196/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1207 - val_loss: 0.1966\n",
      "Epoch 197/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1332 - val_loss: 0.1846\n",
      "Epoch 198/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1199 - val_loss: 0.1852\n",
      "Epoch 199/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1196 - val_loss: 0.1896\n",
      "Epoch 200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1196 - val_loss: 0.1886\n",
      "Epoch 201/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1211 - val_loss: 0.1914\n",
      "Epoch 202/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1326 - val_loss: 0.1882\n",
      "Epoch 203/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1194 - val_loss: 0.1867\n",
      "Epoch 204/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1171 - val_loss: 0.1880\n",
      "Epoch 205/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1174 - val_loss: 0.1897\n",
      "Epoch 206/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1185 - val_loss: 0.1889\n",
      "Epoch 207/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1193 - val_loss: 0.1980\n",
      "Epoch 208/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1199 - val_loss: 0.1847\n",
      "Epoch 209/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1185 - val_loss: 0.1913\n",
      "Epoch 210/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1231 - val_loss: 0.1945\n",
      "Epoch 211/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1206 - val_loss: 0.1850\n",
      "Epoch 212/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1159 - val_loss: 0.1912\n",
      "Epoch 213/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1168 - val_loss: 0.1865\n",
      "Epoch 214/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1185 - val_loss: 0.1982\n",
      "Epoch 215/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1195 - val_loss: 0.1917\n",
      "Epoch 216/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1168 - val_loss: 0.1886\n",
      "Epoch 217/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1186 - val_loss: 0.1884\n",
      "Epoch 218/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1175 - val_loss: 0.1886\n",
      "Epoch 219/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1155 - val_loss: 0.1905\n",
      "Epoch 220/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1155 - val_loss: 0.1884\n",
      "Epoch 221/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1166 - val_loss: 0.1901\n",
      "Epoch 222/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1185 - val_loss: 0.1962\n",
      "Epoch 223/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1161 - val_loss: 0.2003\n",
      "Epoch 224/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1189 - val_loss: 0.1910\n",
      "Epoch 225/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1179 - val_loss: 0.1959\n",
      "Epoch 226/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1155 - val_loss: 0.1889\n",
      "Epoch 227/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1146 - val_loss: 0.1878\n",
      "Epoch 228/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1194 - val_loss: 0.1943\n",
      "Epoch 229/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1144 - val_loss: 0.1870\n",
      "Epoch 230/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1130 - val_loss: 0.1887\n",
      "Epoch 231/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1130 - val_loss: 0.1895\n",
      "Epoch 232/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1242 - val_loss: 0.1832\n",
      "Epoch 233/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1118 - val_loss: 0.1928\n",
      "Epoch 234/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1133 - val_loss: 0.1879\n",
      "Epoch 235/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1121 - val_loss: 0.1911\n",
      "Epoch 236/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1149 - val_loss: 0.1896\n",
      "Epoch 237/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1140 - val_loss: 0.1909\n",
      "Epoch 238/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1125 - val_loss: 0.2093\n",
      "Epoch 239/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1149 - val_loss: 0.1908\n",
      "Epoch 240/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1137 - val_loss: 0.2020\n",
      "Epoch 241/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1226 - val_loss: 0.1852\n",
      "Epoch 242/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1107 - val_loss: 0.1882\n",
      "Epoch 243/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1099 - val_loss: 0.1969\n",
      "Epoch 244/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1130 - val_loss: 0.1940\n",
      "Epoch 245/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1252 - val_loss: 0.2391\n",
      "Epoch 246/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1165 - val_loss: 0.1865\n",
      "Epoch 247/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1089 - val_loss: 0.1920\n",
      "Epoch 248/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1093 - val_loss: 0.1888\n",
      "Epoch 249/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1171 - val_loss: 0.1865\n",
      "Epoch 250/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1093 - val_loss: 0.1970\n",
      "Epoch 251/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1258 - val_loss: 0.1896\n",
      "Epoch 252/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1081 - val_loss: 0.1889\n",
      "Epoch 253/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1093 - val_loss: 0.1908\n",
      "Epoch 254/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1089 - val_loss: 0.1918\n",
      "Epoch 255/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1102 - val_loss: 0.1892\n",
      "Epoch 256/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1080 - val_loss: 0.1947\n",
      "Epoch 257/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1115 - val_loss: 0.2406\n",
      "Epoch 258/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1153 - val_loss: 0.1911\n",
      "Epoch 259/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1083 - val_loss: 0.1970\n",
      "Epoch 260/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1143 - val_loss: 0.2014\n",
      "Epoch 261/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1126 - val_loss: 0.1885\n",
      "Epoch 262/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1069 - val_loss: 0.1991\n",
      "Epoch 263/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1071 - val_loss: 0.1987\n",
      "Epoch 264/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1091 - val_loss: 0.1935\n",
      "Epoch 265/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1081 - val_loss: 0.1927\n",
      "Epoch 266/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1097 - val_loss: 0.1956\n",
      "Epoch 267/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1129 - val_loss: 0.1955\n",
      "Epoch 268/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1097 - val_loss: 0.2014\n",
      "Epoch 269/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1083 - val_loss: 0.1944\n",
      "Epoch 270/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1082 - val_loss: 0.1935\n",
      "Epoch 271/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1160 - val_loss: 0.1947\n",
      "Epoch 272/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1073 - val_loss: 0.1931\n",
      "Epoch 273/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1075 - val_loss: 0.1974\n",
      "Epoch 274/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1067 - val_loss: 0.1999\n",
      "Epoch 275/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1061 - val_loss: 0.2012\n",
      "Epoch 276/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1105 - val_loss: 0.1934\n",
      "Epoch 277/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1060 - val_loss: 0.1989\n",
      "Epoch 278/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1062 - val_loss: 0.1971\n",
      "Epoch 279/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1097 - val_loss: 0.2051\n",
      "Epoch 280/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1134 - val_loss: 0.1955\n",
      "Epoch 281/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1063 - val_loss: 0.1971\n",
      "Epoch 282/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1086 - val_loss: 0.1980\n",
      "Epoch 283/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1059 - val_loss: 0.1902\n",
      "Epoch 284/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1057 - val_loss: 0.1950\n",
      "Epoch 285/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1079 - val_loss: 0.2009\n",
      "Epoch 286/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1058 - val_loss: 0.1972\n",
      "Epoch 287/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1064 - val_loss: 0.1937\n",
      "Epoch 288/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1043 - val_loss: 0.2093\n",
      "Epoch 289/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1073 - val_loss: 0.2096\n",
      "Epoch 290/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1065 - val_loss: 0.1958\n",
      "Epoch 291/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1067 - val_loss: 0.1951\n",
      "Epoch 292/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1050 - val_loss: 0.2049\n",
      "Epoch 293/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1076 - val_loss: 0.1971\n",
      "Epoch 294/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1068 - val_loss: 0.1936\n",
      "Epoch 295/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1046 - val_loss: 0.2006\n",
      "Epoch 296/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1053 - val_loss: 0.2052\n",
      "Epoch 297/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1079 - val_loss: 0.1981\n",
      "Epoch 298/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1063 - val_loss: 0.1989\n",
      "Epoch 299/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1027 - val_loss: 0.1987\n",
      "Epoch 300/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1035 - val_loss: 0.2057\n",
      "Epoch 301/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1032 - val_loss: 0.2009\n",
      "Epoch 302/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1047 - val_loss: 0.1994\n",
      "Epoch 303/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1026 - val_loss: 0.1964\n",
      "Epoch 304/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1112 - val_loss: 0.1947\n",
      "Epoch 305/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1043 - val_loss: 0.1959\n",
      "Epoch 306/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1015 - val_loss: 0.2024\n",
      "Epoch 307/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1023 - val_loss: 0.2060\n",
      "Epoch 308/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1063 - val_loss: 0.1996\n",
      "Epoch 309/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1051 - val_loss: 0.2051\n",
      "Epoch 310/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1046 - val_loss: 0.2041\n",
      "Epoch 311/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1015 - val_loss: 0.1983\n",
      "Epoch 312/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1043 - val_loss: 0.2055\n",
      "Epoch 313/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1053 - val_loss: 0.2051\n",
      "Epoch 314/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1013 - val_loss: 0.1995\n",
      "Epoch 315/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1129 - val_loss: 0.1992\n",
      "Epoch 316/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1047 - val_loss: 0.2019\n",
      "Epoch 317/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0993 - val_loss: 0.2010\n",
      "Epoch 318/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1015 - val_loss: 0.2011\n",
      "Epoch 319/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1002 - val_loss: 0.2004\n",
      "Epoch 320/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1032 - val_loss: 0.2061\n",
      "Epoch 321/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1010 - val_loss: 0.2041\n",
      "Epoch 322/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1011 - val_loss: 0.2035\n",
      "Epoch 323/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1000 - val_loss: 0.2016\n",
      "Epoch 324/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1023 - val_loss: 0.2091\n",
      "Epoch 325/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1081 - val_loss: 0.2003\n",
      "Epoch 326/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1016 - val_loss: 0.2014\n",
      "Epoch 327/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0994 - val_loss: 0.1982\n",
      "Epoch 328/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1019 - val_loss: 0.2004\n",
      "Epoch 329/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0993 - val_loss: 0.2047\n",
      "Epoch 330/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1017 - val_loss: 0.2014\n",
      "Epoch 331/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1004 - val_loss: 0.2059\n",
      "Epoch 332/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1008 - val_loss: 0.2079\n",
      "Epoch 333/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1039 - val_loss: 0.2072\n",
      "Epoch 334/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1074 - val_loss: 0.2018\n",
      "Epoch 335/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1004 - val_loss: 0.2019\n",
      "Epoch 336/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0987 - val_loss: 0.2042\n",
      "Epoch 337/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0991 - val_loss: 0.1993\n",
      "Epoch 338/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1042 - val_loss: 0.2069\n",
      "Epoch 339/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1173 - val_loss: 0.1999\n",
      "Epoch 340/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0988 - val_loss: 0.1970\n",
      "Epoch 341/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0962 - val_loss: 0.1983\n",
      "Epoch 342/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0971 - val_loss: 0.2037\n",
      "Epoch 343/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0979 - val_loss: 0.2117\n",
      "Epoch 344/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0995 - val_loss: 0.2030\n",
      "Epoch 345/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1008 - val_loss: 0.2383\n",
      "Epoch 346/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1020 - val_loss: 0.2001\n",
      "Epoch 347/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0973 - val_loss: 0.2195\n",
      "Epoch 348/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1087 - val_loss: 0.1998\n",
      "Epoch 349/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0979 - val_loss: 0.2020\n",
      "Epoch 350/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0972 - val_loss: 0.2038\n",
      "Epoch 351/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0958 - val_loss: 0.2458\n",
      "Epoch 352/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1149 - val_loss: 0.2093\n",
      "Epoch 353/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0962 - val_loss: 0.2033\n",
      "Epoch 354/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0962 - val_loss: 0.2042\n",
      "Epoch 355/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0961 - val_loss: 0.2182\n",
      "Epoch 356/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0995 - val_loss: 0.2092\n",
      "Epoch 357/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0975 - val_loss: 0.2090\n",
      "Epoch 358/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1006 - val_loss: 0.2034\n",
      "Epoch 359/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0987 - val_loss: 0.2118\n",
      "Epoch 360/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0960 - val_loss: 0.2063\n",
      "Epoch 361/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1011 - val_loss: 0.2052\n",
      "Epoch 362/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0959 - val_loss: 0.2060\n",
      "Epoch 363/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0959 - val_loss: 0.2147\n",
      "Epoch 364/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0998 - val_loss: 0.2075\n",
      "Epoch 365/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1034 - val_loss: 0.2105\n",
      "Epoch 366/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0992 - val_loss: 0.2141\n",
      "Epoch 367/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0955 - val_loss: 0.2135\n",
      "Epoch 368/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0964 - val_loss: 0.2098\n",
      "Epoch 369/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0995 - val_loss: 0.2226\n",
      "Epoch 370/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1010 - val_loss: 0.2034\n",
      "Epoch 371/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0960 - val_loss: 0.2092\n",
      "Epoch 372/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0978 - val_loss: 0.2122\n",
      "Epoch 373/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1019 - val_loss: 0.2108\n",
      "Epoch 374/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0959 - val_loss: 0.2064\n",
      "Epoch 375/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0940 - val_loss: 0.2194\n",
      "Epoch 376/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0976 - val_loss: 0.2062\n",
      "Epoch 377/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0974 - val_loss: 0.2261\n",
      "Epoch 378/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0996 - val_loss: 0.2080\n",
      "Epoch 379/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0938 - val_loss: 0.2085\n",
      "Epoch 380/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0955 - val_loss: 0.2159\n",
      "Epoch 381/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0967 - val_loss: 0.2152\n",
      "Epoch 382/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1083 - val_loss: 0.2091\n",
      "Epoch 383/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0934 - val_loss: 0.2052\n",
      "Epoch 384/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0925 - val_loss: 0.2177\n",
      "Epoch 385/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0941 - val_loss: 0.2143\n",
      "Epoch 386/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0959 - val_loss: 0.2115\n",
      "Epoch 387/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1006 - val_loss: 0.2320\n",
      "Epoch 388/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1020 - val_loss: 0.2046\n",
      "Epoch 389/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0941 - val_loss: 0.2112\n",
      "Epoch 390/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1067 - val_loss: 0.2079\n",
      "Epoch 391/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0937 - val_loss: 0.2091\n",
      "Epoch 392/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0931 - val_loss: 0.2093\n",
      "Epoch 393/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0935 - val_loss: 0.2133\n",
      "Epoch 394/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0927 - val_loss: 0.2178\n",
      "Epoch 395/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0942 - val_loss: 0.2109\n",
      "Epoch 396/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1001 - val_loss: 0.2151\n",
      "Epoch 397/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0964 - val_loss: 0.2113\n",
      "Epoch 398/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0925 - val_loss: 0.2202\n",
      "Epoch 399/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0928 - val_loss: 0.2189\n",
      "Epoch 400/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0932 - val_loss: 0.2108\n",
      "Epoch 401/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0942 - val_loss: 0.2124\n",
      "Epoch 402/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0968 - val_loss: 0.2134\n",
      "Epoch 403/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0946 - val_loss: 0.2242\n",
      "Epoch 404/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0970 - val_loss: 0.2146\n",
      "Epoch 405/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0949 - val_loss: 0.2079\n",
      "Epoch 406/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0927 - val_loss: 0.2160\n",
      "Epoch 407/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0965 - val_loss: 0.2225\n",
      "Epoch 408/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0955 - val_loss: 0.2245\n",
      "Epoch 409/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0951 - val_loss: 0.2405\n",
      "Epoch 410/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1016 - val_loss: 0.2114\n",
      "Epoch 411/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0922 - val_loss: 0.2179\n",
      "Epoch 412/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0941 - val_loss: 0.2371\n",
      "Epoch 413/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0939 - val_loss: 0.2120\n",
      "Epoch 414/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0913 - val_loss: 0.2116\n",
      "Epoch 415/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0932 - val_loss: 0.2136\n",
      "Epoch 416/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0932 - val_loss: 0.2174\n",
      "Epoch 417/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0942 - val_loss: 0.2200\n",
      "Epoch 418/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0999 - val_loss: 0.2100\n",
      "Epoch 419/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0913 - val_loss: 0.2202\n",
      "Epoch 420/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0900 - val_loss: 0.2143\n",
      "Epoch 421/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0926 - val_loss: 0.2185\n",
      "Epoch 422/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1187 - val_loss: 0.2125\n",
      "Epoch 423/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0938 - val_loss: 0.2140\n",
      "Epoch 424/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0894 - val_loss: 0.2189\n",
      "Epoch 425/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0932 - val_loss: 0.2111\n",
      "Epoch 426/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0904 - val_loss: 0.2196\n",
      "Epoch 427/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0904 - val_loss: 0.2223\n",
      "Epoch 428/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0906 - val_loss: 0.2159\n",
      "Epoch 429/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0934 - val_loss: 0.2174\n",
      "Epoch 430/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0972 - val_loss: 0.2248\n",
      "Epoch 431/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0934 - val_loss: 0.2161\n",
      "Epoch 432/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0905 - val_loss: 0.2234\n",
      "Epoch 433/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0912 - val_loss: 0.2215\n",
      "Epoch 434/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0911 - val_loss: 0.2264\n",
      "Epoch 435/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0977 - val_loss: 0.2229\n",
      "Epoch 436/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0940 - val_loss: 0.2215\n",
      "Epoch 437/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0943 - val_loss: 0.2177\n",
      "Epoch 438/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0912 - val_loss: 0.2186\n",
      "Epoch 439/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0907 - val_loss: 0.2167\n",
      "Epoch 440/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0921 - val_loss: 0.2200\n",
      "Epoch 441/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0936 - val_loss: 0.2317\n",
      "Epoch 442/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0972 - val_loss: 0.2280\n",
      "Epoch 443/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0928 - val_loss: 0.2175\n",
      "Epoch 444/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0905 - val_loss: 0.2400\n",
      "Epoch 445/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0920 - val_loss: 0.2239\n",
      "Epoch 446/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0904 - val_loss: 0.2335\n",
      "Epoch 447/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0941 - val_loss: 0.2284\n",
      "Epoch 448/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0903 - val_loss: 0.2217\n",
      "Epoch 449/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0917 - val_loss: 0.2211\n",
      "Epoch 450/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1101 - val_loss: 0.2261\n",
      "Epoch 451/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0891 - val_loss: 0.2156\n",
      "Epoch 452/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0869 - val_loss: 0.2165\n",
      "Epoch 453/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0896 - val_loss: 0.2205\n",
      "Epoch 454/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0902 - val_loss: 0.2205\n",
      "Epoch 455/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0944 - val_loss: 0.2251\n",
      "Epoch 456/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0908 - val_loss: 0.2277\n",
      "Epoch 457/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0887 - val_loss: 0.2253\n",
      "Epoch 458/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0914 - val_loss: 0.2359\n",
      "Epoch 459/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0935 - val_loss: 0.2434\n",
      "Epoch 460/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0954 - val_loss: 0.2141\n",
      "Epoch 461/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0891 - val_loss: 0.2156\n",
      "Epoch 462/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0916 - val_loss: 0.2308\n",
      "Epoch 463/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0924 - val_loss: 0.2211\n",
      "Epoch 464/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0891 - val_loss: 0.2206\n",
      "Epoch 465/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0888 - val_loss: 0.2245\n",
      "Epoch 466/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0913 - val_loss: 0.2291\n",
      "Epoch 467/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0910 - val_loss: 0.2275\n",
      "Epoch 468/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0885 - val_loss: 0.2218\n",
      "Epoch 469/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0956 - val_loss: 0.2177\n",
      "Epoch 470/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0893 - val_loss: 0.2242\n",
      "Epoch 471/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1027 - val_loss: 0.2243\n",
      "Epoch 472/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0900 - val_loss: 0.2196\n",
      "Epoch 473/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0857 - val_loss: 0.2204\n",
      "Epoch 474/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0860 - val_loss: 0.2210\n",
      "Epoch 475/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0882 - val_loss: 0.2279\n",
      "Epoch 476/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0912 - val_loss: 0.2210\n",
      "Epoch 477/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0898 - val_loss: 0.2223\n",
      "Epoch 478/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0883 - val_loss: 0.2248\n",
      "Epoch 479/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0933 - val_loss: 0.2466\n",
      "Epoch 480/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0922 - val_loss: 0.2246\n",
      "Epoch 481/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0879 - val_loss: 0.2265\n",
      "Epoch 482/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0891 - val_loss: 0.2250\n",
      "Epoch 483/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0863 - val_loss: 0.2222\n",
      "Epoch 484/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0912 - val_loss: 0.2401\n",
      "Epoch 485/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0929 - val_loss: 0.2282\n",
      "Epoch 486/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0886 - val_loss: 0.2317\n",
      "Epoch 487/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0944 - val_loss: 0.2196\n",
      "Epoch 488/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0876 - val_loss: 0.2252\n",
      "Epoch 489/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0874 - val_loss: 0.2263\n",
      "Epoch 490/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0883 - val_loss: 0.2228\n",
      "Epoch 491/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0917 - val_loss: 0.2437\n",
      "Epoch 492/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0893 - val_loss: 0.2313\n",
      "Epoch 493/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0909 - val_loss: 0.2255\n",
      "Epoch 494/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0955 - val_loss: 0.2260\n",
      "Epoch 495/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0882 - val_loss: 0.2268\n",
      "Epoch 496/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0881 - val_loss: 0.2417\n",
      "Epoch 497/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0994 - val_loss: 0.2206\n",
      "Epoch 498/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0863 - val_loss: 0.2207\n",
      "Epoch 499/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0857 - val_loss: 0.2640\n",
      "Epoch 500/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0933 - val_loss: 0.2270\n",
      "Epoch 501/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0857 - val_loss: 0.2258\n",
      "Epoch 502/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1023 - val_loss: 0.2318\n",
      "Epoch 503/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0874 - val_loss: 0.2223\n",
      "Epoch 504/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0837 - val_loss: 0.2295\n",
      "Epoch 505/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0839 - val_loss: 0.2282\n",
      "Epoch 506/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0854 - val_loss: 0.2285\n",
      "Epoch 507/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0898 - val_loss: 0.2365\n",
      "Epoch 508/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0966 - val_loss: 0.2276\n",
      "Epoch 509/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0866 - val_loss: 0.2263\n",
      "Epoch 510/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0868 - val_loss: 0.2250\n",
      "Epoch 511/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0879 - val_loss: 0.2270\n",
      "Epoch 512/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0853 - val_loss: 0.2345\n",
      "Epoch 513/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0897 - val_loss: 0.2332\n",
      "Epoch 514/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0872 - val_loss: 0.2397\n",
      "Epoch 515/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0872 - val_loss: 0.2410\n",
      "Epoch 516/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0898 - val_loss: 0.2323\n",
      "Epoch 517/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0971 - val_loss: 0.2272\n",
      "Epoch 518/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0863 - val_loss: 0.2304\n",
      "Epoch 519/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0866 - val_loss: 0.2414\n",
      "Epoch 520/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0870 - val_loss: 0.2327\n",
      "Epoch 521/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0872 - val_loss: 0.2272\n",
      "Epoch 522/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0857 - val_loss: 0.2294\n",
      "Epoch 523/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0874 - val_loss: 0.2367\n",
      "Epoch 524/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0917 - val_loss: 0.2287\n",
      "Epoch 525/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0873 - val_loss: 0.2314\n",
      "Epoch 526/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0850 - val_loss: 0.2339\n",
      "Epoch 527/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0887 - val_loss: 0.2479\n",
      "Epoch 528/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0931 - val_loss: 0.2277\n",
      "Epoch 529/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1052 - val_loss: 0.2245\n",
      "Epoch 530/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0845 - val_loss: 0.2257\n",
      "Epoch 531/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0832 - val_loss: 0.2267\n",
      "Epoch 532/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0826 - val_loss: 0.2254\n",
      "Epoch 533/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0875 - val_loss: 0.2511\n",
      "Epoch 534/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0912 - val_loss: 0.2384\n",
      "Epoch 535/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0862 - val_loss: 0.2346\n",
      "Epoch 536/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0842 - val_loss: 0.2465\n",
      "Epoch 537/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0865 - val_loss: 0.2333\n",
      "Epoch 538/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0874 - val_loss: 0.2312\n",
      "Epoch 539/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0884 - val_loss: 0.2292\n",
      "Epoch 540/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0848 - val_loss: 0.2328\n",
      "Epoch 541/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0873 - val_loss: 0.2537\n",
      "Epoch 542/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0932 - val_loss: 0.2264\n",
      "Epoch 543/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0847 - val_loss: 0.2394\n",
      "Epoch 544/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0979 - val_loss: 0.2412\n",
      "Epoch 545/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0887 - val_loss: 0.2256\n",
      "Epoch 546/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0834 - val_loss: 0.2268\n",
      "Epoch 547/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0861 - val_loss: 0.2481\n",
      "Epoch 548/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0851 - val_loss: 0.2373\n",
      "Epoch 549/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0824 - val_loss: 0.2357\n",
      "Epoch 550/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0829 - val_loss: 0.2372\n",
      "Epoch 551/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0854 - val_loss: 0.2422\n",
      "Epoch 552/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0871 - val_loss: 0.2302\n",
      "Epoch 553/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0864 - val_loss: 0.2481\n",
      "Epoch 554/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0870 - val_loss: 0.2290\n",
      "Epoch 555/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0860 - val_loss: 0.2314\n",
      "Epoch 556/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0924 - val_loss: 0.2337\n",
      "Epoch 557/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0880 - val_loss: 0.2329\n",
      "Epoch 558/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0836 - val_loss: 0.2366\n",
      "Epoch 559/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0954 - val_loss: 0.2693\n",
      "Epoch 560/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0934 - val_loss: 0.2312\n",
      "Epoch 561/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0818 - val_loss: 0.2304\n",
      "Epoch 562/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0812 - val_loss: 0.2430\n",
      "Epoch 563/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0977 - val_loss: 0.2485\n",
      "Epoch 564/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0860 - val_loss: 0.2270\n",
      "Epoch 565/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0819 - val_loss: 0.2291\n",
      "Epoch 566/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0820 - val_loss: 0.2308\n",
      "Epoch 567/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0891 - val_loss: 0.2396\n",
      "Epoch 568/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0835 - val_loss: 0.2440\n",
      "Epoch 569/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0846 - val_loss: 0.2444\n",
      "Epoch 570/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0836 - val_loss: 0.2380\n",
      "Epoch 571/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0854 - val_loss: 0.2510\n",
      "Epoch 572/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0974 - val_loss: 0.2346\n",
      "Epoch 573/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0840 - val_loss: 0.2376\n",
      "Epoch 574/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0823 - val_loss: 0.2362\n",
      "Epoch 575/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1012 - val_loss: 0.2344\n",
      "Epoch 576/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0822 - val_loss: 0.2295\n",
      "Epoch 577/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0806 - val_loss: 0.2375\n",
      "Epoch 578/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0809 - val_loss: 0.2358\n",
      "Epoch 579/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0883 - val_loss: 0.2380\n",
      "Epoch 580/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0862 - val_loss: 0.2413\n",
      "Epoch 581/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0852 - val_loss: 0.2500\n",
      "Epoch 582/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0858 - val_loss: 0.2359\n",
      "Epoch 583/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0833 - val_loss: 0.2413\n",
      "Epoch 584/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0870 - val_loss: 0.2374\n",
      "Epoch 585/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0827 - val_loss: 0.2383\n",
      "Epoch 586/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0870 - val_loss: 0.2539\n",
      "Epoch 587/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0844 - val_loss: 0.2383\n",
      "Epoch 588/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0843 - val_loss: 0.2514\n",
      "Epoch 589/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0956 - val_loss: 0.2428\n",
      "Epoch 590/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0809 - val_loss: 0.2360\n",
      "Epoch 591/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0817 - val_loss: 0.2440\n",
      "Epoch 592/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0830 - val_loss: 0.2468\n",
      "Epoch 593/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0936 - val_loss: 0.2488\n",
      "Epoch 594/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0868 - val_loss: 0.2301\n",
      "Epoch 595/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0817 - val_loss: 0.2317\n",
      "Epoch 596/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0805 - val_loss: 0.2456\n",
      "Epoch 597/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0820 - val_loss: 0.2349\n",
      "Epoch 598/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0959 - val_loss: 0.2779\n",
      "Epoch 599/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0923 - val_loss: 0.2339\n",
      "Epoch 600/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0807 - val_loss: 0.2376\n",
      "Epoch 601/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0805 - val_loss: 0.2492\n",
      "Epoch 602/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0819 - val_loss: 0.2411\n",
      "Epoch 603/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0822 - val_loss: 0.2413\n",
      "Epoch 604/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0955 - val_loss: 0.2423\n",
      "Epoch 605/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0849 - val_loss: 0.2366\n",
      "Epoch 606/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0809 - val_loss: 0.2411\n",
      "Epoch 607/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0891 - val_loss: 0.2403\n",
      "Epoch 608/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0822 - val_loss: 0.2352\n",
      "Epoch 609/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0802 - val_loss: 0.2376\n",
      "Epoch 610/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0856 - val_loss: 0.2412\n",
      "Epoch 611/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0901 - val_loss: 0.2391\n",
      "Epoch 612/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0817 - val_loss: 0.2460\n",
      "Epoch 613/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0807 - val_loss: 0.2413\n",
      "Epoch 614/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0819 - val_loss: 0.2476\n",
      "Epoch 615/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0809 - val_loss: 0.2489\n",
      "Epoch 616/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0849 - val_loss: 0.2548\n",
      "Epoch 617/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0916 - val_loss: 0.2425\n",
      "Epoch 618/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0867 - val_loss: 0.2449\n",
      "Epoch 619/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0825 - val_loss: 0.2380\n",
      "Epoch 620/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0834 - val_loss: 0.2442\n",
      "Epoch 621/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0847 - val_loss: 0.2390\n",
      "Epoch 622/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0814 - val_loss: 0.2405\n",
      "Epoch 623/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0810 - val_loss: 0.2590\n",
      "Epoch 624/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0801 - val_loss: 0.2460\n",
      "Epoch 625/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0795 - val_loss: 0.2492\n",
      "Epoch 626/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0813 - val_loss: 0.2393\n",
      "Epoch 627/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0836 - val_loss: 0.2905\n",
      "Epoch 628/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0941 - val_loss: 0.2482\n",
      "Epoch 629/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0830 - val_loss: 0.2562\n",
      "Epoch 630/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0821 - val_loss: 0.2399\n",
      "Epoch 631/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0840 - val_loss: 0.2483\n",
      "Epoch 632/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0830 - val_loss: 0.2437\n",
      "Epoch 633/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0815 - val_loss: 0.2518\n",
      "Epoch 634/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0816 - val_loss: 0.2470\n",
      "Epoch 635/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0835 - val_loss: 0.2464\n",
      "Epoch 636/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0980 - val_loss: 0.2412\n",
      "Epoch 637/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0798 - val_loss: 0.2464\n",
      "Epoch 638/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0812 - val_loss: 0.2535\n",
      "Epoch 639/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0833 - val_loss: 0.2439\n",
      "Epoch 640/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0813 - val_loss: 0.2452\n",
      "Epoch 641/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0822 - val_loss: 0.2429\n",
      "Epoch 642/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0820 - val_loss: 0.2470\n",
      "Epoch 643/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0917 - val_loss: 0.2504\n",
      "Epoch 644/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0813 - val_loss: 0.2514\n",
      "Epoch 645/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0831 - val_loss: 0.2569\n",
      "Epoch 646/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0794 - val_loss: 0.2476\n",
      "Epoch 647/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0803 - val_loss: 0.2514\n",
      "Epoch 648/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1010 - val_loss: 0.2564\n",
      "Epoch 649/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0880 - val_loss: 0.2385\n",
      "Epoch 650/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0790 - val_loss: 0.2464\n",
      "Epoch 651/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0777 - val_loss: 0.2545\n",
      "Epoch 652/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0797 - val_loss: 0.2449\n",
      "Epoch 653/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0818 - val_loss: 0.2412\n",
      "Epoch 654/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0791 - val_loss: 0.2516\n",
      "Epoch 655/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0798 - val_loss: 0.2483\n",
      "Epoch 656/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0871 - val_loss: 0.2855\n",
      "Epoch 657/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1025 - val_loss: 0.2384\n",
      "Epoch 658/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0779 - val_loss: 0.2490\n",
      "Epoch 659/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0795 - val_loss: 0.2502\n",
      "Epoch 660/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0792 - val_loss: 0.2430\n",
      "Epoch 661/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0782 - val_loss: 0.2478\n",
      "Epoch 662/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0781 - val_loss: 0.2505\n",
      "Epoch 663/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0804 - val_loss: 0.2504\n",
      "Epoch 664/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0826 - val_loss: 0.2604\n",
      "Epoch 665/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0819 - val_loss: 0.2793\n",
      "Epoch 666/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0971 - val_loss: 0.2464\n",
      "Epoch 667/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0806 - val_loss: 0.2571\n",
      "Epoch 668/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0918 - val_loss: 0.2488\n",
      "Epoch 669/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0780 - val_loss: 0.2454\n",
      "Epoch 670/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0773 - val_loss: 0.2449\n",
      "Epoch 671/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0778 - val_loss: 0.2495\n",
      "Epoch 672/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0874 - val_loss: 0.2510\n",
      "Epoch 673/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0801 - val_loss: 0.2487\n",
      "Epoch 674/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0779 - val_loss: 0.2501\n",
      "Epoch 675/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0830 - val_loss: 0.2537\n",
      "Epoch 676/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0812 - val_loss: 0.2626\n",
      "Epoch 677/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0891 - val_loss: 0.2564\n",
      "Epoch 678/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0808 - val_loss: 0.2553\n",
      "Epoch 679/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0796 - val_loss: 0.2552\n",
      "Epoch 680/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0782 - val_loss: 0.2486\n",
      "Epoch 681/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0804 - val_loss: 0.2518\n",
      "Epoch 682/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0859 - val_loss: 0.2587\n",
      "Epoch 683/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0934 - val_loss: 0.2578\n",
      "Epoch 684/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0952 - val_loss: 0.2395\n",
      "Epoch 685/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0776 - val_loss: 0.2439\n",
      "Epoch 686/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0753 - val_loss: 0.2497\n",
      "Epoch 687/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0786 - val_loss: 0.2453\n",
      "Epoch 688/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0789 - val_loss: 0.2494\n",
      "Epoch 689/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0819 - val_loss: 0.2502\n",
      "Epoch 690/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0810 - val_loss: 0.2498\n",
      "Epoch 691/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0770 - val_loss: 0.2546\n",
      "Epoch 692/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0787 - val_loss: 0.2536\n",
      "Epoch 693/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0827 - val_loss: 0.2529\n",
      "Epoch 694/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0843 - val_loss: 0.2569\n",
      "Epoch 695/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0826 - val_loss: 0.2620\n",
      "Epoch 696/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0896 - val_loss: 0.2605\n",
      "Epoch 697/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0835 - val_loss: 0.2500\n",
      "Epoch 698/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0781 - val_loss: 0.2487\n",
      "Epoch 699/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0769 - val_loss: 0.2493\n",
      "Epoch 700/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0783 - val_loss: 0.2563\n",
      "Epoch 701/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0901 - val_loss: 0.2586\n",
      "Epoch 702/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0845 - val_loss: 0.2557\n",
      "Epoch 703/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0785 - val_loss: 0.2485\n",
      "Epoch 704/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0776 - val_loss: 0.2506\n",
      "Epoch 705/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0854 - val_loss: 0.2516\n",
      "Epoch 706/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0774 - val_loss: 0.2534\n",
      "Epoch 707/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0778 - val_loss: 0.2573\n",
      "Epoch 708/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0794 - val_loss: 0.2574\n",
      "Epoch 709/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0802 - val_loss: 0.2585\n",
      "Epoch 710/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0810 - val_loss: 0.2648\n",
      "Epoch 711/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0820 - val_loss: 0.2722\n",
      "Epoch 712/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0848 - val_loss: 0.2670\n",
      "Epoch 713/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0803 - val_loss: 0.2540\n",
      "Epoch 714/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0779 - val_loss: 0.2608\n",
      "Epoch 715/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0789 - val_loss: 0.2532\n",
      "Epoch 716/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0777 - val_loss: 0.2554\n",
      "Epoch 717/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0903 - val_loss: 0.2502\n",
      "Epoch 718/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0781 - val_loss: 0.2541\n",
      "Epoch 719/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0864 - val_loss: 0.2505\n",
      "Epoch 720/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0779 - val_loss: 0.2530\n",
      "Epoch 721/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0810 - val_loss: 0.2526\n",
      "Epoch 722/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0801 - val_loss: 0.2539\n",
      "Epoch 723/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0787 - val_loss: 0.2592\n",
      "Epoch 724/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0799 - val_loss: 0.2486\n",
      "Epoch 725/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0794 - val_loss: 0.2668\n",
      "Epoch 726/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0832 - val_loss: 0.2644\n",
      "Epoch 727/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0850 - val_loss: 0.2537\n",
      "Epoch 728/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0767 - val_loss: 0.2552\n",
      "Epoch 729/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0768 - val_loss: 0.2546\n",
      "Epoch 730/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0798 - val_loss: 0.2611\n",
      "Epoch 731/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0802 - val_loss: 0.2586\n",
      "Epoch 732/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0826 - val_loss: 0.2582\n",
      "Epoch 733/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0829 - val_loss: 0.2575\n",
      "Epoch 734/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0824 - val_loss: 0.2527\n",
      "Epoch 735/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0773 - val_loss: 0.2583\n",
      "Epoch 736/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0770 - val_loss: 0.2608\n",
      "Epoch 737/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0842 - val_loss: 0.2521\n",
      "Epoch 738/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0805 - val_loss: 0.2562\n",
      "Epoch 739/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0760 - val_loss: 0.2577\n",
      "Epoch 740/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0918 - val_loss: 0.2710\n",
      "Epoch 741/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0851 - val_loss: 0.2514\n",
      "Epoch 742/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0760 - val_loss: 0.2507\n",
      "Epoch 743/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0761 - val_loss: 0.2578\n",
      "Epoch 744/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0810 - val_loss: 0.2712\n",
      "Epoch 745/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0889 - val_loss: 0.2609\n",
      "Epoch 746/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0776 - val_loss: 0.2517\n",
      "Epoch 747/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0737 - val_loss: 0.2553\n",
      "Epoch 748/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0754 - val_loss: 0.2592\n",
      "Epoch 749/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0823 - val_loss: 0.2669\n",
      "Epoch 750/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0797 - val_loss: 0.2550\n",
      "Epoch 751/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0787 - val_loss: 0.2642\n",
      "Epoch 752/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0774 - val_loss: 0.2575\n",
      "Epoch 753/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0815 - val_loss: 0.2675\n",
      "Epoch 754/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0782 - val_loss: 0.2600\n",
      "Epoch 755/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0790 - val_loss: 0.2629\n",
      "Epoch 756/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1022 - val_loss: 0.2580\n",
      "Epoch 757/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0785 - val_loss: 0.2508\n",
      "Epoch 758/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0742 - val_loss: 0.2598\n",
      "Epoch 759/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0755 - val_loss: 0.2525\n",
      "Epoch 760/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0789 - val_loss: 0.2577\n",
      "Epoch 761/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0765 - val_loss: 0.2613\n",
      "Epoch 762/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0738 - val_loss: 0.2621\n",
      "Epoch 763/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0782 - val_loss: 0.2644\n",
      "Epoch 764/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0782 - val_loss: 0.2583\n",
      "Epoch 765/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0766 - val_loss: 0.2617\n",
      "Epoch 766/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0920 - val_loss: 0.2827\n",
      "Epoch 767/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0859 - val_loss: 0.2525\n",
      "Epoch 768/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0770 - val_loss: 0.2574\n",
      "Epoch 769/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0766 - val_loss: 0.2549\n",
      "Epoch 770/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0748 - val_loss: 0.2702\n",
      "Epoch 771/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0784 - val_loss: 0.2677\n",
      "Epoch 772/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0781 - val_loss: 0.2571\n",
      "Epoch 773/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0774 - val_loss: 0.2601\n",
      "Epoch 774/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0771 - val_loss: 0.2635\n",
      "Epoch 775/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0982 - val_loss: 0.2980\n",
      "Epoch 776/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0866 - val_loss: 0.2560\n",
      "Epoch 777/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.2521\n",
      "Epoch 778/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0755 - val_loss: 0.2547\n",
      "Epoch 779/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0774 - val_loss: 0.2577\n",
      "Epoch 780/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0770 - val_loss: 0.2608\n",
      "Epoch 781/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0736 - val_loss: 0.2597\n",
      "Epoch 782/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0772 - val_loss: 0.2615\n",
      "Epoch 783/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0996 - val_loss: 0.2552\n",
      "Epoch 784/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0761 - val_loss: 0.2536\n",
      "Epoch 785/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0729 - val_loss: 0.2628\n",
      "Epoch 786/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0724 - val_loss: 0.2610\n",
      "Epoch 787/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0751 - val_loss: 0.2728\n",
      "Epoch 788/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0984 - val_loss: 0.2608\n",
      "Epoch 789/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0740 - val_loss: 0.2548\n",
      "Epoch 790/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0741 - val_loss: 0.2560\n",
      "Epoch 791/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0726 - val_loss: 0.2596\n",
      "Epoch 792/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0759 - val_loss: 0.2722\n",
      "Epoch 793/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0803 - val_loss: 0.2644\n",
      "Epoch 794/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0876 - val_loss: 0.2676\n",
      "Epoch 795/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0818 - val_loss: 0.2608\n",
      "Epoch 796/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0741 - val_loss: 0.2711\n",
      "Epoch 797/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0768 - val_loss: 0.2724\n",
      "Epoch 798/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0791 - val_loss: 0.2599\n",
      "Epoch 799/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0738 - val_loss: 0.2582\n",
      "Epoch 800/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0734 - val_loss: 0.2716\n",
      "Epoch 801/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1025 - val_loss: 0.2644\n",
      "Epoch 802/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0810 - val_loss: 0.2553\n",
      "Epoch 803/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0730 - val_loss: 0.2533\n",
      "Epoch 804/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.2958\n",
      "Epoch 805/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0789 - val_loss: 0.2570\n",
      "Epoch 806/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0727 - val_loss: 0.2610\n",
      "Epoch 807/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0755 - val_loss: 0.2590\n",
      "Epoch 808/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0764 - val_loss: 0.2664\n",
      "Epoch 809/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0765 - val_loss: 0.2655\n",
      "Epoch 810/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0755 - val_loss: 0.2655\n",
      "Epoch 811/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0752 - val_loss: 0.2630\n",
      "Epoch 812/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0770 - val_loss: 0.2697\n",
      "Epoch 813/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0827 - val_loss: 0.2863\n",
      "Epoch 814/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0851 - val_loss: 0.2792\n",
      "Epoch 815/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0873 - val_loss: 0.2679\n",
      "Epoch 816/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0755 - val_loss: 0.2605\n",
      "Epoch 817/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0736 - val_loss: 0.2668\n",
      "Epoch 818/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0764 - val_loss: 0.2698\n",
      "Epoch 819/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0782 - val_loss: 0.2663\n",
      "Epoch 820/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0754 - val_loss: 0.2639\n",
      "Epoch 821/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0734 - val_loss: 0.2718\n",
      "Epoch 822/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0777 - val_loss: 0.2721\n",
      "Epoch 823/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0811 - val_loss: 0.2621\n",
      "Epoch 824/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0773 - val_loss: 0.2636\n",
      "Epoch 825/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0736 - val_loss: 0.2657\n",
      "Epoch 826/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0741 - val_loss: 0.2693\n",
      "Epoch 827/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0858 - val_loss: 0.2612\n",
      "Epoch 828/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0741 - val_loss: 0.2680\n",
      "Epoch 829/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0772 - val_loss: 0.2715\n",
      "Epoch 830/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0791 - val_loss: 0.2674\n",
      "Epoch 831/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0752 - val_loss: 0.2754\n",
      "Epoch 832/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0778 - val_loss: 0.2729\n",
      "Epoch 833/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.2611\n",
      "Epoch 834/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0747 - val_loss: 0.2719\n",
      "Epoch 835/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0799 - val_loss: 0.2830\n",
      "Epoch 836/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0972 - val_loss: 0.2689\n",
      "Epoch 837/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0772 - val_loss: 0.2618\n",
      "Epoch 838/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0715 - val_loss: 0.2569\n",
      "Epoch 839/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0728 - val_loss: 0.2638\n",
      "Epoch 840/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0742 - val_loss: 0.2653\n",
      "Epoch 841/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0834 - val_loss: 0.2671\n",
      "Epoch 842/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0758 - val_loss: 0.2815\n",
      "Epoch 843/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0762 - val_loss: 0.2739\n",
      "Epoch 844/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.2673\n",
      "Epoch 845/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0841 - val_loss: 0.2765\n",
      "Epoch 846/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0812 - val_loss: 0.2667\n",
      "Epoch 847/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0759 - val_loss: 0.2641\n",
      "Epoch 848/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0722 - val_loss: 0.2641\n",
      "Epoch 849/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0830 - val_loss: 0.2843\n",
      "Epoch 850/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0792 - val_loss: 0.2658\n",
      "Epoch 851/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0732 - val_loss: 0.2709\n",
      "Epoch 852/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0745 - val_loss: 0.2657\n",
      "Epoch 853/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0724 - val_loss: 0.2645\n",
      "Epoch 854/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0794 - val_loss: 0.2820\n",
      "Epoch 855/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0817 - val_loss: 0.2652\n",
      "Epoch 856/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0743 - val_loss: 0.2664\n",
      "Epoch 857/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0734 - val_loss: 0.2704\n",
      "Epoch 858/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0823 - val_loss: 0.2721\n",
      "Epoch 859/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0827 - val_loss: 0.2678\n",
      "Epoch 860/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0744 - val_loss: 0.2908\n",
      "Epoch 861/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0753 - val_loss: 0.2697\n",
      "Epoch 862/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0731 - val_loss: 0.3230\n",
      "Epoch 863/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0847 - val_loss: 0.2625\n",
      "Epoch 864/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0731 - val_loss: 0.2732\n",
      "Epoch 865/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0725 - val_loss: 0.2720\n",
      "Epoch 866/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0742 - val_loss: 0.2696\n",
      "Epoch 867/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0768 - val_loss: 0.2688\n",
      "Epoch 868/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0777 - val_loss: 0.2816\n",
      "Epoch 869/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0796 - val_loss: 0.2871\n",
      "Epoch 870/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0789 - val_loss: 0.2702\n",
      "Epoch 871/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0759 - val_loss: 0.2829\n",
      "Epoch 872/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0789 - val_loss: 0.2681\n",
      "Epoch 873/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0725 - val_loss: 0.2617\n",
      "Epoch 874/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0758 - val_loss: 0.2764\n",
      "Epoch 875/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0787 - val_loss: 0.2965\n",
      "Epoch 876/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0807 - val_loss: 0.2712\n",
      "Epoch 877/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0851 - val_loss: 0.3037\n",
      "Epoch 878/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0818 - val_loss: 0.2667\n",
      "Epoch 879/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0715 - val_loss: 0.2622\n",
      "Epoch 880/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0705 - val_loss: 0.2690\n",
      "Epoch 881/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0720 - val_loss: 0.2708\n",
      "Epoch 882/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0705 - val_loss: 0.2707\n",
      "Epoch 883/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0748 - val_loss: 0.2978\n",
      "Epoch 884/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0821 - val_loss: 0.2663\n",
      "Epoch 885/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0743 - val_loss: 0.2743\n",
      "Epoch 886/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0790 - val_loss: 0.2684\n",
      "Epoch 887/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0775 - val_loss: 0.2745\n",
      "Epoch 888/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0762 - val_loss: 0.2718\n",
      "Epoch 889/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0797 - val_loss: 0.2904\n",
      "Epoch 890/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0849 - val_loss: 0.2657\n",
      "Epoch 891/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0712 - val_loss: 0.2664\n",
      "Epoch 892/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0721 - val_loss: 0.2713\n",
      "Epoch 893/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0732 - val_loss: 0.2743\n",
      "Epoch 894/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0749 - val_loss: 0.2728\n",
      "Epoch 895/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0929 - val_loss: 0.2680\n",
      "Epoch 896/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0725 - val_loss: 0.2707\n",
      "Epoch 897/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0712 - val_loss: 0.2721\n",
      "Epoch 898/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0711 - val_loss: 0.2785\n",
      "Epoch 899/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0755 - val_loss: 0.2777\n",
      "Epoch 900/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0748 - val_loss: 0.2732\n",
      "Epoch 901/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0961 - val_loss: 0.2640\n",
      "Epoch 902/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0717 - val_loss: 0.2720\n",
      "Epoch 903/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0708 - val_loss: 0.2760\n",
      "Epoch 904/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0707 - val_loss: 0.2754\n",
      "Epoch 905/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0728 - val_loss: 0.2791\n",
      "Epoch 906/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0734 - val_loss: 0.2754\n",
      "Epoch 907/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0732 - val_loss: 0.2765\n",
      "Epoch 908/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0797 - val_loss: 0.2784\n",
      "Epoch 909/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0923 - val_loss: 0.2866\n",
      "Epoch 910/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0791 - val_loss: 0.2726\n",
      "Epoch 911/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0710 - val_loss: 0.2698\n",
      "Epoch 912/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0707 - val_loss: 0.2954\n",
      "Epoch 913/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0781 - val_loss: 0.2710\n",
      "Epoch 914/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0733 - val_loss: 0.2900\n",
      "Epoch 915/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0740 - val_loss: 0.2787\n",
      "Epoch 916/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0743 - val_loss: 0.2789\n",
      "Epoch 917/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0729 - val_loss: 0.2766\n",
      "Epoch 918/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0817 - val_loss: 0.2798\n",
      "Epoch 919/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0808 - val_loss: 0.2717\n",
      "Epoch 920/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0721 - val_loss: 0.2739\n",
      "Epoch 921/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0756 - val_loss: 0.2794\n",
      "Epoch 922/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0719 - val_loss: 0.2852\n",
      "Epoch 923/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0709 - val_loss: 0.2753\n",
      "Epoch 924/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0747 - val_loss: 0.2844\n",
      "Epoch 925/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0792 - val_loss: 0.2715\n",
      "Epoch 926/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0758 - val_loss: 0.2764\n",
      "Epoch 927/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0709 - val_loss: 0.2814\n",
      "Epoch 928/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0739 - val_loss: 0.2798\n",
      "Epoch 929/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0885 - val_loss: 0.2846\n",
      "Epoch 930/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0720 - val_loss: 0.2791\n",
      "Epoch 931/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0746 - val_loss: 0.2785\n",
      "Epoch 932/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0759 - val_loss: 0.2739\n",
      "Epoch 933/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0702 - val_loss: 0.2808\n",
      "Epoch 934/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0710 - val_loss: 0.2742\n",
      "Epoch 935/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0719 - val_loss: 0.2827\n",
      "Epoch 936/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0749 - val_loss: 0.2842\n",
      "Epoch 937/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0784 - val_loss: 0.3017\n",
      "Epoch 938/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0915 - val_loss: 0.2752\n",
      "Epoch 939/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0737 - val_loss: 0.2741\n",
      "Epoch 940/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0720 - val_loss: 0.2774\n",
      "Epoch 941/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0759 - val_loss: 0.2763\n",
      "Epoch 942/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0749 - val_loss: 0.2760\n",
      "Epoch 943/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0703 - val_loss: 0.2763\n",
      "Epoch 944/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0701 - val_loss: 0.2802\n",
      "Epoch 945/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0736 - val_loss: 0.2853\n",
      "Epoch 946/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0753 - val_loss: 0.2804\n",
      "Epoch 947/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0756 - val_loss: 0.2916\n",
      "Epoch 948/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0756 - val_loss: 0.2838\n",
      "Epoch 949/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0902 - val_loss: 0.2796\n",
      "Epoch 950/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0738 - val_loss: 0.2825\n",
      "Epoch 951/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0700 - val_loss: 0.2761\n",
      "Epoch 952/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0823 - val_loss: 0.2948\n",
      "Epoch 953/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0844 - val_loss: 0.2691\n",
      "Epoch 954/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0718 - val_loss: 0.2796\n",
      "Epoch 955/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0702 - val_loss: 0.2763\n",
      "Epoch 956/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0701 - val_loss: 0.2773\n",
      "Epoch 957/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0728 - val_loss: 0.2803\n",
      "Epoch 958/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0728 - val_loss: 0.2871\n",
      "Epoch 959/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0719 - val_loss: 0.2864\n",
      "Epoch 960/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0808 - val_loss: 0.2905\n",
      "Epoch 961/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0794 - val_loss: 0.2857\n",
      "Epoch 962/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0766 - val_loss: 0.2807\n",
      "Epoch 963/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0775 - val_loss: 0.2787\n",
      "Epoch 964/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0693 - val_loss: 0.2729\n",
      "Epoch 965/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0684 - val_loss: 0.2764\n",
      "Epoch 966/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0684 - val_loss: 0.2838\n",
      "Epoch 967/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0712 - val_loss: 0.2844\n",
      "Epoch 968/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0811 - val_loss: 0.2884\n",
      "Epoch 969/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0811 - val_loss: 0.2777\n",
      "Epoch 970/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0734 - val_loss: 0.2858\n",
      "Epoch 971/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0711 - val_loss: 0.2844\n",
      "Epoch 972/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0717 - val_loss: 0.2848\n",
      "Epoch 973/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0737 - val_loss: 0.2955\n",
      "Epoch 974/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0722 - val_loss: 0.2778\n",
      "Epoch 975/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0783 - val_loss: 0.3214\n",
      "Epoch 976/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0831 - val_loss: 0.2798\n",
      "Epoch 977/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0726 - val_loss: 0.2809\n",
      "Epoch 978/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0711 - val_loss: 0.2803\n",
      "Epoch 979/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0717 - val_loss: 0.2790\n",
      "Epoch 980/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0712 - val_loss: 0.2798\n",
      "Epoch 981/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0778 - val_loss: 0.2763\n",
      "Epoch 982/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0748 - val_loss: 0.2857\n",
      "Epoch 983/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0792 - val_loss: 0.2829\n",
      "Epoch 984/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0797 - val_loss: 0.2783\n",
      "Epoch 985/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0703 - val_loss: 0.2774\n",
      "Epoch 986/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0720 - val_loss: 0.2819\n",
      "Epoch 987/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0718 - val_loss: 0.2841\n",
      "Epoch 988/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0725 - val_loss: 0.2838\n",
      "Epoch 989/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0795 - val_loss: 0.2856\n",
      "Epoch 990/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0747 - val_loss: 0.2835\n",
      "Epoch 991/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0702 - val_loss: 0.2733\n",
      "Epoch 992/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0721 - val_loss: 0.2986\n",
      "Epoch 993/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0784 - val_loss: 0.2825\n",
      "Epoch 994/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0718 - val_loss: 0.2897\n",
      "Epoch 995/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0701 - val_loss: 0.2969\n",
      "Epoch 996/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0743 - val_loss: 0.2831\n",
      "Epoch 997/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0852 - val_loss: 0.2755\n",
      "Epoch 998/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0767 - val_loss: 0.2760\n",
      "Epoch 999/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0719 - val_loss: 0.2930\n",
      "Epoch 1000/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0706 - val_loss: 0.2851\n",
      "Epoch 1001/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0760 - val_loss: 0.2993\n",
      "Epoch 1002/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0834 - val_loss: 0.2795\n",
      "Epoch 1003/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0691 - val_loss: 0.2801\n",
      "Epoch 1004/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0693 - val_loss: 0.2824\n",
      "Epoch 1005/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0700 - val_loss: 0.2773\n",
      "Epoch 1006/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0767 - val_loss: 0.2982\n",
      "Epoch 1007/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0866 - val_loss: 0.2789\n",
      "Epoch 1008/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0688 - val_loss: 0.2772\n",
      "Epoch 1009/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0693 - val_loss: 0.2805\n",
      "Epoch 1010/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0689 - val_loss: 0.2885\n",
      "Epoch 1011/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0691 - val_loss: 0.3157\n",
      "Epoch 1012/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0762 - val_loss: 0.2798\n",
      "Epoch 1013/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0730 - val_loss: 0.2799\n",
      "Epoch 1014/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0745 - val_loss: 0.2894\n",
      "Epoch 1015/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0742 - val_loss: 0.2861\n",
      "Epoch 1016/2000\n",
      "15000/15000 [==============================] - 1s 65us/step - loss: 0.0732 - val_loss: 0.2947\n",
      "Epoch 1017/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0832 - val_loss: 0.2984\n",
      "Epoch 1018/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0768 - val_loss: 0.2751\n",
      "Epoch 1019/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0717 - val_loss: 0.2858\n",
      "Epoch 1020/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0704 - val_loss: 0.2845\n",
      "Epoch 1021/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0700 - val_loss: 0.2821\n",
      "Epoch 1022/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0684 - val_loss: 0.2796\n",
      "Epoch 1023/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0784 - val_loss: 0.2927\n",
      "Epoch 1024/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0767 - val_loss: 0.2907\n",
      "Epoch 1025/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0708 - val_loss: 0.2778\n",
      "Epoch 1026/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0728 - val_loss: 0.2937\n",
      "Epoch 1027/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0689 - val_loss: 0.2866\n",
      "Epoch 1028/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0708 - val_loss: 0.2881\n",
      "Epoch 1029/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0794 - val_loss: 0.3343\n",
      "Epoch 1030/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0950 - val_loss: 0.2990\n",
      "Epoch 1031/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0756 - val_loss: 0.2771\n",
      "Epoch 1032/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0675 - val_loss: 0.2754\n",
      "Epoch 1033/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0664 - val_loss: 0.2827\n",
      "Epoch 1034/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0709 - val_loss: 0.2900\n",
      "Epoch 1035/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0720 - val_loss: 0.2878\n",
      "Epoch 1036/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0746 - val_loss: 0.2860\n",
      "Epoch 1037/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0693 - val_loss: 0.2886\n",
      "Epoch 1038/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0703 - val_loss: 0.2968\n",
      "Epoch 1039/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0710 - val_loss: 0.2905\n",
      "Epoch 1040/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.2953\n",
      "Epoch 1041/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0784 - val_loss: 0.3122\n",
      "Epoch 1042/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0842 - val_loss: 0.2812\n",
      "Epoch 1043/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0682 - val_loss: 0.2842\n",
      "Epoch 1044/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0694 - val_loss: 0.2829\n",
      "Epoch 1045/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0751 - val_loss: 0.3113\n",
      "Epoch 1046/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0814 - val_loss: 0.2791\n",
      "Epoch 1047/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0686 - val_loss: 0.2884\n",
      "Epoch 1048/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0661 - val_loss: 0.2828\n",
      "Epoch 1049/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0670 - val_loss: 0.2912\n",
      "Epoch 1050/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0954 - val_loss: 0.2770\n",
      "Epoch 1051/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0704 - val_loss: 0.2953\n",
      "Epoch 1052/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0674 - val_loss: 0.2865\n",
      "Epoch 1053/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0661 - val_loss: 0.2867\n",
      "Epoch 1054/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0682 - val_loss: 0.2858\n",
      "Epoch 1055/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0690 - val_loss: 0.2921\n",
      "Epoch 1056/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0706 - val_loss: 0.2848\n",
      "Epoch 1057/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0902 - val_loss: 0.3080\n",
      "Epoch 1058/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0756 - val_loss: 0.2823\n",
      "Epoch 1059/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0773 - val_loss: 0.2869\n",
      "Epoch 1060/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0683 - val_loss: 0.2798\n",
      "Epoch 1061/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0659 - val_loss: 0.2846\n",
      "Epoch 1062/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0669 - val_loss: 0.2882\n",
      "Epoch 1063/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0707 - val_loss: 0.2950\n",
      "Epoch 1064/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0705 - val_loss: 0.2906\n",
      "Epoch 1065/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0720 - val_loss: 0.2953\n",
      "Epoch 1066/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0972 - val_loss: 0.2871\n",
      "Epoch 1067/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0719 - val_loss: 0.2823\n",
      "Epoch 1068/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0680 - val_loss: 0.2817\n",
      "Epoch 1069/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0650 - val_loss: 0.2861\n",
      "Epoch 1070/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0709 - val_loss: 0.3053\n",
      "Epoch 1071/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0945 - val_loss: 0.2808\n",
      "Epoch 1072/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0681 - val_loss: 0.2834\n",
      "Epoch 1073/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0668 - val_loss: 0.2877\n",
      "Epoch 1074/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0680 - val_loss: 0.2937\n",
      "Epoch 1075/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0728 - val_loss: 0.2973\n",
      "Epoch 1076/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0717 - val_loss: 0.2831\n",
      "Epoch 1077/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0682 - val_loss: 0.2907\n",
      "Epoch 1078/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0705 - val_loss: 0.2868\n",
      "Epoch 1079/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0894 - val_loss: 0.3019\n",
      "Epoch 1080/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0787 - val_loss: 0.2782\n",
      "Epoch 1081/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0668 - val_loss: 0.2828\n",
      "Epoch 1082/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0681 - val_loss: 0.2868\n",
      "Epoch 1083/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0662 - val_loss: 0.2898\n",
      "Epoch 1084/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0668 - val_loss: 0.2930\n",
      "Epoch 1085/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0678 - val_loss: 0.2943\n",
      "Epoch 1086/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0718 - val_loss: 0.2998\n",
      "Epoch 1087/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1008 - val_loss: 0.2879\n",
      "Epoch 1088/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0711 - val_loss: 0.2774\n",
      "Epoch 1089/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0667 - val_loss: 0.2837\n",
      "Epoch 1090/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0668 - val_loss: 0.2927\n",
      "Epoch 1091/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0727 - val_loss: 0.2931\n",
      "Epoch 1092/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0711 - val_loss: 0.2988\n",
      "Epoch 1093/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0709 - val_loss: 0.2970\n",
      "Epoch 1094/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0753 - val_loss: 0.2935\n",
      "Epoch 1095/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0719 - val_loss: 0.2903\n",
      "Epoch 1096/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0681 - val_loss: 0.2837\n",
      "Epoch 1097/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0701 - val_loss: 0.2870\n",
      "Epoch 1098/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0725 - val_loss: 0.2868\n",
      "Epoch 1099/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0830 - val_loss: 0.2933\n",
      "Epoch 1100/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0710 - val_loss: 0.2841\n",
      "Epoch 1101/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0673 - val_loss: 0.2875\n",
      "Epoch 1102/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0662 - val_loss: 0.2977\n",
      "Epoch 1103/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0680 - val_loss: 0.2899\n",
      "Epoch 1104/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0818 - val_loss: 0.2941\n",
      "Epoch 1105/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0766 - val_loss: 0.3257\n",
      "Epoch 1106/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0806 - val_loss: 0.2907\n",
      "Epoch 1107/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0701 - val_loss: 0.2869\n",
      "Epoch 1108/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0667 - val_loss: 0.2887\n",
      "Epoch 1109/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0954 - val_loss: 0.2796\n",
      "Epoch 1110/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0713 - val_loss: 0.2812\n",
      "Epoch 1111/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0661 - val_loss: 0.2868\n",
      "Epoch 1112/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0636 - val_loss: 0.2915\n",
      "Epoch 1113/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0737 - val_loss: 0.2960\n",
      "Epoch 1114/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0710 - val_loss: 0.2946\n",
      "Epoch 1115/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0681 - val_loss: 0.2873\n",
      "Epoch 1116/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0659 - val_loss: 0.2903\n",
      "Epoch 1117/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0803 - val_loss: 0.2993\n",
      "Epoch 1118/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0674 - val_loss: 0.2936\n",
      "Epoch 1119/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0680 - val_loss: 0.2968\n",
      "Epoch 1120/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0681 - val_loss: 0.3066\n",
      "Epoch 1121/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0753 - val_loss: 0.2965\n",
      "Epoch 1122/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0801 - val_loss: 0.3147\n",
      "Epoch 1123/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0794 - val_loss: 0.2920\n",
      "Epoch 1124/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0675 - val_loss: 0.2904\n",
      "Epoch 1125/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0674 - val_loss: 0.2868\n",
      "Epoch 1126/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0658 - val_loss: 0.2939\n",
      "Epoch 1127/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0690 - val_loss: 0.2907\n",
      "Epoch 1128/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0740 - val_loss: 0.3143\n",
      "Epoch 1129/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0837 - val_loss: 0.2912\n",
      "Epoch 1130/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0691 - val_loss: 0.2864\n",
      "Epoch 1131/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0642 - val_loss: 0.2942\n",
      "Epoch 1132/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0674 - val_loss: 0.2947\n",
      "Epoch 1133/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0691 - val_loss: 0.2948\n",
      "Epoch 1134/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0805 - val_loss: 0.3036\n",
      "Epoch 1135/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0733 - val_loss: 0.2935\n",
      "Epoch 1136/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0723 - val_loss: 0.2957\n",
      "Epoch 1137/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0729 - val_loss: 0.2957\n",
      "Epoch 1138/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0678 - val_loss: 0.2880\n",
      "Epoch 1139/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0645 - val_loss: 0.2940\n",
      "Epoch 1140/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0707 - val_loss: 0.2910\n",
      "Epoch 1141/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0794 - val_loss: 0.3905\n",
      "Epoch 1142/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0892 - val_loss: 0.2863\n",
      "Epoch 1143/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0678 - val_loss: 0.2983\n",
      "Epoch 1144/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0672 - val_loss: 0.2939\n",
      "Epoch 1145/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0665 - val_loss: 0.2925\n",
      "Epoch 1146/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0674 - val_loss: 0.2927\n",
      "Epoch 1147/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0694 - val_loss: 0.3076\n",
      "Epoch 1148/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0740 - val_loss: 0.3020\n",
      "Epoch 1149/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0694 - val_loss: 0.2971\n",
      "Epoch 1150/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0790 - val_loss: 0.2984\n",
      "Epoch 1151/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0705 - val_loss: 0.2859\n",
      "Epoch 1152/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0699 - val_loss: 0.2899\n",
      "Epoch 1153/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0684 - val_loss: 0.2978\n",
      "Epoch 1154/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0704 - val_loss: 0.2935\n",
      "Epoch 1155/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0700 - val_loss: 0.3110\n",
      "Epoch 1156/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0725 - val_loss: 0.2939\n",
      "Epoch 1157/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0785 - val_loss: 0.2974\n",
      "Epoch 1158/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0726 - val_loss: 0.2977\n",
      "Epoch 1159/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0703 - val_loss: 0.2951\n",
      "Epoch 1160/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0663 - val_loss: 0.2938\n",
      "Epoch 1161/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0659 - val_loss: 0.2966\n",
      "Epoch 1162/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0729 - val_loss: 0.3042\n",
      "Epoch 1163/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0707 - val_loss: 0.3021\n",
      "Epoch 1164/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0746 - val_loss: 0.2969\n",
      "Epoch 1165/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0708 - val_loss: 0.2994\n",
      "Epoch 1166/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0686 - val_loss: 0.3067\n",
      "Epoch 1167/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0719 - val_loss: 0.2897\n",
      "Epoch 1168/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0690 - val_loss: 0.2955\n",
      "Epoch 1169/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0757 - val_loss: 0.3517\n",
      "Epoch 1170/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0972 - val_loss: 0.2821\n",
      "Epoch 1171/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0647 - val_loss: 0.2961\n",
      "Epoch 1172/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0643 - val_loss: 0.2916\n",
      "Epoch 1173/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0641 - val_loss: 0.2927\n",
      "Epoch 1174/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0664 - val_loss: 0.2990\n",
      "Epoch 1175/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0665 - val_loss: 0.2982\n",
      "Epoch 1176/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0973 - val_loss: 0.2909\n",
      "Epoch 1177/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0704 - val_loss: 0.2906\n",
      "Epoch 1178/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0647 - val_loss: 0.2940\n",
      "Epoch 1179/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0648 - val_loss: 0.2936\n",
      "Epoch 1180/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0665 - val_loss: 0.2974\n",
      "Epoch 1181/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0842 - val_loss: 0.2956\n",
      "Epoch 1182/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0686 - val_loss: 0.2967\n",
      "Epoch 1183/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0724 - val_loss: 0.2927\n",
      "Epoch 1184/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0658 - val_loss: 0.2935\n",
      "Epoch 1185/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0648 - val_loss: 0.2929\n",
      "Epoch 1186/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0656 - val_loss: 0.2913\n",
      "Epoch 1187/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0695 - val_loss: 0.2994\n",
      "Epoch 1188/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0712 - val_loss: 0.3246\n",
      "Epoch 1189/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0807 - val_loss: 0.2969\n",
      "Epoch 1190/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0707 - val_loss: 0.3010\n",
      "Epoch 1191/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0737 - val_loss: 0.3027\n",
      "Epoch 1192/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0672 - val_loss: 0.2902\n",
      "Epoch 1193/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0651 - val_loss: 0.3004\n",
      "Epoch 1194/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0656 - val_loss: 0.3041\n",
      "Epoch 1195/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0755 - val_loss: 0.2919\n",
      "Epoch 1196/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0901 - val_loss: 0.3043\n",
      "Epoch 1197/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0723 - val_loss: 0.2910\n",
      "Epoch 1198/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0635 - val_loss: 0.2910\n",
      "Epoch 1199/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3042\n",
      "Epoch 1200/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0651 - val_loss: 0.2963\n",
      "Epoch 1201/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0700 - val_loss: 0.3031\n",
      "Epoch 1202/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0814 - val_loss: 0.2944\n",
      "Epoch 1203/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0705 - val_loss: 0.2947\n",
      "Epoch 1204/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0656 - val_loss: 0.2967\n",
      "Epoch 1205/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0658 - val_loss: 0.3016\n",
      "Epoch 1206/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0682 - val_loss: 0.3041\n",
      "Epoch 1207/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0708 - val_loss: 0.3025\n",
      "Epoch 1208/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0800 - val_loss: 0.2960\n",
      "Epoch 1209/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0672 - val_loss: 0.3004\n",
      "Epoch 1210/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0654 - val_loss: 0.3003\n",
      "Epoch 1211/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0812 - val_loss: 0.2979\n",
      "Epoch 1212/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0683 - val_loss: 0.2924\n",
      "Epoch 1213/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0666 - val_loss: 0.2947\n",
      "Epoch 1214/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0722 - val_loss: 0.3298\n",
      "Epoch 1215/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0796 - val_loss: 0.3103\n",
      "Epoch 1216/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0678 - val_loss: 0.2984\n",
      "Epoch 1217/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0649 - val_loss: 0.3081\n",
      "Epoch 1218/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0679 - val_loss: 0.2992\n",
      "Epoch 1219/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0678 - val_loss: 0.3044\n",
      "Epoch 1220/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0706 - val_loss: 0.2972\n",
      "Epoch 1221/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0764 - val_loss: 0.3108\n",
      "Epoch 1222/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0716 - val_loss: 0.2963\n",
      "Epoch 1223/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0664 - val_loss: 0.2973\n",
      "Epoch 1224/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0636 - val_loss: 0.3052\n",
      "Epoch 1225/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0733 - val_loss: 0.3326\n",
      "Epoch 1226/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0749 - val_loss: 0.2958\n",
      "Epoch 1227/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0666 - val_loss: 0.2985\n",
      "Epoch 1228/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0664 - val_loss: 0.3016\n",
      "Epoch 1229/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0683 - val_loss: 0.2988\n",
      "Epoch 1230/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0690 - val_loss: 0.3020\n",
      "Epoch 1231/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0686 - val_loss: 0.3003\n",
      "Epoch 1232/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0657 - val_loss: 0.3028\n",
      "Epoch 1233/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0829 - val_loss: 0.3199\n",
      "Epoch 1234/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0798 - val_loss: 0.3046\n",
      "Epoch 1235/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0786 - val_loss: 0.2894\n",
      "Epoch 1236/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0667 - val_loss: 0.2936\n",
      "Epoch 1237/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0627 - val_loss: 0.2955\n",
      "Epoch 1238/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0642 - val_loss: 0.2961\n",
      "Epoch 1239/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0636 - val_loss: 0.3004\n",
      "Epoch 1240/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0680 - val_loss: 0.3158\n",
      "Epoch 1241/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0776 - val_loss: 0.3134\n",
      "Epoch 1242/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0908 - val_loss: 0.2892\n",
      "Epoch 1243/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0651 - val_loss: 0.2960\n",
      "Epoch 1244/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0640 - val_loss: 0.2967\n",
      "Epoch 1245/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0639 - val_loss: 0.2976\n",
      "Epoch 1246/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0639 - val_loss: 0.3064\n",
      "Epoch 1247/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0653 - val_loss: 0.3163\n",
      "Epoch 1248/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0700 - val_loss: 0.3066\n",
      "Epoch 1249/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0682 - val_loss: 0.3120\n",
      "Epoch 1250/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0959 - val_loss: 0.3065\n",
      "Epoch 1251/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0726 - val_loss: 0.2962\n",
      "Epoch 1252/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0629 - val_loss: 0.2960\n",
      "Epoch 1253/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0622 - val_loss: 0.3024\n",
      "Epoch 1254/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0621 - val_loss: 0.3101\n",
      "Epoch 1255/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0752 - val_loss: 0.3064\n",
      "Epoch 1256/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0757 - val_loss: 0.3072\n",
      "Epoch 1257/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0655 - val_loss: 0.3021\n",
      "Epoch 1258/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0639 - val_loss: 0.2994\n",
      "Epoch 1259/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0630 - val_loss: 0.3062\n",
      "Epoch 1260/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0668 - val_loss: 0.3317\n",
      "Epoch 1261/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0818 - val_loss: 0.3128\n",
      "Epoch 1262/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0727 - val_loss: 0.3094\n",
      "Epoch 1263/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0699 - val_loss: 0.3109\n",
      "Epoch 1264/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0668 - val_loss: 0.3145\n",
      "Epoch 1265/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0670 - val_loss: 0.2979\n",
      "Epoch 1266/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0642 - val_loss: 0.3067\n",
      "Epoch 1267/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0782 - val_loss: 0.3000\n",
      "Epoch 1268/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0661 - val_loss: 0.3002\n",
      "Epoch 1269/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0675 - val_loss: 0.3060\n",
      "Epoch 1270/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0681 - val_loss: 0.3126\n",
      "Epoch 1271/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0679 - val_loss: 0.3079\n",
      "Epoch 1272/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0672 - val_loss: 0.3141\n",
      "Epoch 1273/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0688 - val_loss: 0.3032\n",
      "Epoch 1274/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0664 - val_loss: 0.3070\n",
      "Epoch 1275/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0747 - val_loss: 0.3076\n",
      "Epoch 1276/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0718 - val_loss: 0.3008\n",
      "Epoch 1277/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0673 - val_loss: 0.3018\n",
      "Epoch 1278/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0638 - val_loss: 0.3296\n",
      "Epoch 1279/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0782 - val_loss: 0.3409\n",
      "Epoch 1280/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0826 - val_loss: 0.3023\n",
      "Epoch 1281/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3030\n",
      "Epoch 1282/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0665 - val_loss: 0.3037\n",
      "Epoch 1283/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0651 - val_loss: 0.3077\n",
      "Epoch 1284/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0880 - val_loss: 0.2980\n",
      "Epoch 1285/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0654 - val_loss: 0.2960\n",
      "Epoch 1286/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0619 - val_loss: 0.2963\n",
      "Epoch 1287/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0629 - val_loss: 0.3109\n",
      "Epoch 1288/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0632 - val_loss: 0.3101\n",
      "Epoch 1289/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0835 - val_loss: 0.2960\n",
      "Epoch 1290/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0636 - val_loss: 0.2997\n",
      "Epoch 1291/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0629 - val_loss: 0.3045\n",
      "Epoch 1292/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0811 - val_loss: 0.2998\n",
      "Epoch 1293/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0695 - val_loss: 0.3021\n",
      "Epoch 1294/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0633 - val_loss: 0.3041\n",
      "Epoch 1295/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0617 - val_loss: 0.3063\n",
      "Epoch 1296/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0651 - val_loss: 0.3059\n",
      "Epoch 1297/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0739 - val_loss: 0.3068\n",
      "Epoch 1298/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0831 - val_loss: 0.3069\n",
      "Epoch 1299/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0743 - val_loss: 0.3053\n",
      "Epoch 1300/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0673 - val_loss: 0.3135\n",
      "Epoch 1301/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0656 - val_loss: 0.3007\n",
      "Epoch 1302/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0641 - val_loss: 0.3107\n",
      "Epoch 1303/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0649 - val_loss: 0.3158\n",
      "Epoch 1304/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0752 - val_loss: 0.3008\n",
      "Epoch 1305/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0662 - val_loss: 0.3008\n",
      "Epoch 1306/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0635 - val_loss: 0.3062\n",
      "Epoch 1307/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0743 - val_loss: 0.3368\n",
      "Epoch 1308/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0808 - val_loss: 0.3015\n",
      "Epoch 1309/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0655 - val_loss: 0.3005\n",
      "Epoch 1310/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0632 - val_loss: 0.3047\n",
      "Epoch 1311/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0664 - val_loss: 0.3052\n",
      "Epoch 1312/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0680 - val_loss: 0.3065\n",
      "Epoch 1313/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0702 - val_loss: 0.3090\n",
      "Epoch 1314/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0813 - val_loss: 0.3095\n",
      "Epoch 1315/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0672 - val_loss: 0.3003\n",
      "Epoch 1316/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0706 - val_loss: 0.3026\n",
      "Epoch 1317/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0668 - val_loss: 0.3065\n",
      "Epoch 1318/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0630 - val_loss: 0.3064\n",
      "Epoch 1319/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0624 - val_loss: 0.3042\n",
      "Epoch 1320/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0668 - val_loss: 0.3424\n",
      "Epoch 1321/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0737 - val_loss: 0.3196\n",
      "Epoch 1322/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0653 - val_loss: 0.3317\n",
      "Epoch 1323/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0706 - val_loss: 0.3156\n",
      "Epoch 1324/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0762 - val_loss: 0.3229\n",
      "Epoch 1325/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0701 - val_loss: 0.3002\n",
      "Epoch 1326/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0634 - val_loss: 0.3097\n",
      "Epoch 1327/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0653 - val_loss: 0.3105\n",
      "Epoch 1328/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0701 - val_loss: 0.3168\n",
      "Epoch 1329/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0685 - val_loss: 0.3037\n",
      "Epoch 1330/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0657 - val_loss: 0.3083\n",
      "Epoch 1331/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0665 - val_loss: 0.3231\n",
      "Epoch 1332/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0709 - val_loss: 0.3103\n",
      "Epoch 1333/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0722 - val_loss: 0.3193\n",
      "Epoch 1334/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0687 - val_loss: 0.3064\n",
      "Epoch 1335/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0634 - val_loss: 0.3150\n",
      "Epoch 1336/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0691 - val_loss: 0.3179\n",
      "Epoch 1337/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0816 - val_loss: 0.3076\n",
      "Epoch 1338/2000\n",
      "15000/15000 [==============================] - 1s 65us/step - loss: 0.0708 - val_loss: 0.3031\n",
      "Epoch 1339/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0611 - val_loss: 0.3064\n",
      "Epoch 1340/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0636 - val_loss: 0.3097\n",
      "Epoch 1341/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0631 - val_loss: 0.3177\n",
      "Epoch 1342/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0687 - val_loss: 0.3220\n",
      "Epoch 1343/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.3084\n",
      "Epoch 1344/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0673 - val_loss: 0.3165\n",
      "Epoch 1345/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0635 - val_loss: 0.3095\n",
      "Epoch 1346/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0647 - val_loss: 0.3158\n",
      "Epoch 1347/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0647 - val_loss: 0.3750\n",
      "Epoch 1348/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0724 - val_loss: 0.3082\n",
      "Epoch 1349/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0646 - val_loss: 0.3158\n",
      "Epoch 1350/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0753 - val_loss: 0.3097\n",
      "Epoch 1351/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3105\n",
      "Epoch 1352/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0669 - val_loss: 0.3184\n",
      "Epoch 1353/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0829 - val_loss: 0.3049\n",
      "Epoch 1354/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0670 - val_loss: 0.3130\n",
      "Epoch 1355/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0665 - val_loss: 0.3096\n",
      "Epoch 1356/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0714 - val_loss: 0.3074\n",
      "Epoch 1357/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0648 - val_loss: 0.3068\n",
      "Epoch 1358/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0629 - val_loss: 0.3112\n",
      "Epoch 1359/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0712 - val_loss: 0.3047\n",
      "Epoch 1360/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0647 - val_loss: 0.3156\n",
      "Epoch 1361/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0662 - val_loss: 0.3166\n",
      "Epoch 1362/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0801 - val_loss: 0.3424\n",
      "Epoch 1363/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0795 - val_loss: 0.3034\n",
      "Epoch 1364/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0628 - val_loss: 0.3037\n",
      "Epoch 1365/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0643 - val_loss: 0.3405\n",
      "Epoch 1366/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0762 - val_loss: 0.2979\n",
      "Epoch 1367/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0621 - val_loss: 0.3072\n",
      "Epoch 1368/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0606 - val_loss: 0.3071\n",
      "Epoch 1369/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0608 - val_loss: 0.3140\n",
      "Epoch 1370/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0646 - val_loss: 0.3154\n",
      "Epoch 1371/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0852 - val_loss: 0.3148\n",
      "Epoch 1372/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0659 - val_loss: 0.3072\n",
      "Epoch 1373/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0655 - val_loss: 0.3166\n",
      "Epoch 1374/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0635 - val_loss: 0.3217\n",
      "Epoch 1375/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0675 - val_loss: 0.3189\n",
      "Epoch 1376/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0705 - val_loss: 0.3199\n",
      "Epoch 1377/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0647 - val_loss: 0.3100\n",
      "Epoch 1378/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0641 - val_loss: 0.3128\n",
      "Epoch 1379/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0829 - val_loss: 0.3369\n",
      "Epoch 1380/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0741 - val_loss: 0.3001\n",
      "Epoch 1381/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0626 - val_loss: 0.3122\n",
      "Epoch 1382/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0627 - val_loss: 0.3095\n",
      "Epoch 1383/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0616 - val_loss: 0.3104\n",
      "Epoch 1384/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0637 - val_loss: 0.3229\n",
      "Epoch 1385/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0672 - val_loss: 0.3135\n",
      "Epoch 1386/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0688 - val_loss: 0.3348\n",
      "Epoch 1387/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0935 - val_loss: 0.3304\n",
      "Epoch 1388/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0683 - val_loss: 0.3060\n",
      "Epoch 1389/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0608 - val_loss: 0.3045\n",
      "Epoch 1390/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0607 - val_loss: 0.3087\n",
      "Epoch 1391/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0608 - val_loss: 0.3262\n",
      "Epoch 1392/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0797 - val_loss: 0.3101\n",
      "Epoch 1393/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0688 - val_loss: 0.3162\n",
      "Epoch 1394/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0622 - val_loss: 0.3137\n",
      "Epoch 1395/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0616 - val_loss: 0.3112\n",
      "Epoch 1396/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0640 - val_loss: 0.3192\n",
      "Epoch 1397/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0701 - val_loss: 0.3088\n",
      "Epoch 1398/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0648 - val_loss: 0.3327\n",
      "Epoch 1399/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0781 - val_loss: 0.3157\n",
      "Epoch 1400/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0734 - val_loss: 0.3086\n",
      "Epoch 1401/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0641 - val_loss: 0.3064\n",
      "Epoch 1402/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0634 - val_loss: 0.3169\n",
      "Epoch 1403/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0645 - val_loss: 0.3089\n",
      "Epoch 1404/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0635 - val_loss: 0.3161\n",
      "Epoch 1405/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0662 - val_loss: 0.3173\n",
      "Epoch 1406/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3160\n",
      "Epoch 1407/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0661 - val_loss: 0.3256\n",
      "Epoch 1408/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0742 - val_loss: 0.3204\n",
      "Epoch 1409/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0717 - val_loss: 0.3073\n",
      "Epoch 1410/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0645 - val_loss: 0.3222\n",
      "Epoch 1411/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0694 - val_loss: 0.3237\n",
      "Epoch 1412/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0709 - val_loss: 0.3298\n",
      "Epoch 1413/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0845 - val_loss: 0.3064\n",
      "Epoch 1414/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0648 - val_loss: 0.3018\n",
      "Epoch 1415/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0610 - val_loss: 0.3030\n",
      "Epoch 1416/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0651 - val_loss: 0.3054\n",
      "Epoch 1417/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0598 - val_loss: 0.3174\n",
      "Epoch 1418/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0608 - val_loss: 0.3126\n",
      "Epoch 1419/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0718 - val_loss: 0.3409\n",
      "Epoch 1420/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0872 - val_loss: 0.3060\n",
      "Epoch 1421/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0658 - val_loss: 0.3173\n",
      "Epoch 1422/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0628 - val_loss: 0.3118\n",
      "Epoch 1423/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0636 - val_loss: 0.3106\n",
      "Epoch 1424/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0716 - val_loss: 0.3106\n",
      "Epoch 1425/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0634 - val_loss: 0.3305\n",
      "Epoch 1426/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0631 - val_loss: 0.3180\n",
      "Epoch 1427/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0667 - val_loss: 0.3280\n",
      "Epoch 1428/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0733 - val_loss: 0.3164\n",
      "Epoch 1429/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3165\n",
      "Epoch 1430/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0692 - val_loss: 0.3132\n",
      "Epoch 1431/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0635 - val_loss: 0.3189\n",
      "Epoch 1432/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0660 - val_loss: 0.3170\n",
      "Epoch 1433/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0658 - val_loss: 0.3231\n",
      "Epoch 1434/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0893 - val_loss: 0.3121\n",
      "Epoch 1435/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0639 - val_loss: 0.3104\n",
      "Epoch 1436/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0602 - val_loss: 0.3099\n",
      "Epoch 1437/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0620 - val_loss: 0.3111\n",
      "Epoch 1438/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0612 - val_loss: 0.3123\n",
      "Epoch 1439/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0939 - val_loss: 0.3191\n",
      "Epoch 1440/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0689 - val_loss: 0.3038\n",
      "Epoch 1441/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0606 - val_loss: 0.3093\n",
      "Epoch 1442/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0594 - val_loss: 0.3123\n",
      "Epoch 1443/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0596 - val_loss: 0.3117\n",
      "Epoch 1444/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0625 - val_loss: 0.3245\n",
      "Epoch 1445/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0802 - val_loss: 0.3119\n",
      "Epoch 1446/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0655 - val_loss: 0.3169\n",
      "Epoch 1447/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0628 - val_loss: 0.3205\n",
      "Epoch 1448/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0640 - val_loss: 0.3192\n",
      "Epoch 1449/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0680 - val_loss: 0.3226\n",
      "Epoch 1450/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0684 - val_loss: 0.3218\n",
      "Epoch 1451/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0671 - val_loss: 0.3142\n",
      "Epoch 1452/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0626 - val_loss: 0.3156\n",
      "Epoch 1453/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0637 - val_loss: 0.3653\n",
      "Epoch 1454/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0746 - val_loss: 0.3144\n",
      "Epoch 1455/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0711 - val_loss: 0.3123\n",
      "Epoch 1456/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0641 - val_loss: 0.3080\n",
      "Epoch 1457/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0633 - val_loss: 0.3163\n",
      "Epoch 1458/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0674 - val_loss: 0.3223\n",
      "Epoch 1459/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0682 - val_loss: 0.3303\n",
      "Epoch 1460/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0736 - val_loss: 0.3097\n",
      "Epoch 1461/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0617 - val_loss: 0.3116\n",
      "Epoch 1462/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0614 - val_loss: 0.3212\n",
      "Epoch 1463/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0685 - val_loss: 0.3231\n",
      "Epoch 1464/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0667 - val_loss: 0.3116\n",
      "Epoch 1465/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0623 - val_loss: 0.3200\n",
      "Epoch 1466/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0656 - val_loss: 0.3298\n",
      "Epoch 1467/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0900 - val_loss: 0.3556\n",
      "Epoch 1468/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0841 - val_loss: 0.3111\n",
      "Epoch 1469/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0626 - val_loss: 0.3050\n",
      "Epoch 1470/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0588 - val_loss: 0.3144\n",
      "Epoch 1471/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0587 - val_loss: 0.3226\n",
      "Epoch 1472/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0696 - val_loss: 0.3121\n",
      "Epoch 1473/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0678 - val_loss: 0.3167\n",
      "Epoch 1474/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0659 - val_loss: 0.3079\n",
      "Epoch 1475/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0610 - val_loss: 0.3138\n",
      "Epoch 1476/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0628 - val_loss: 0.3160\n",
      "Epoch 1477/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0659 - val_loss: 0.3301\n",
      "Epoch 1478/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0708 - val_loss: 0.3493\n",
      "Epoch 1479/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0739 - val_loss: 0.3179\n",
      "Epoch 1480/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0656 - val_loss: 0.3200\n",
      "Epoch 1481/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0616 - val_loss: 0.3119\n",
      "Epoch 1482/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0693 - val_loss: 0.3173\n",
      "Epoch 1483/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0628 - val_loss: 0.3129\n",
      "Epoch 1484/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0624 - val_loss: 0.3160\n",
      "Epoch 1485/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0665 - val_loss: 0.3372\n",
      "Epoch 1486/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0698 - val_loss: 0.3261\n",
      "Epoch 1487/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0632 - val_loss: 0.3262\n",
      "Epoch 1488/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0618 - val_loss: 0.3156\n",
      "Epoch 1489/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0774 - val_loss: 0.3228\n",
      "Epoch 1490/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0692 - val_loss: 0.3215\n",
      "Epoch 1491/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0762 - val_loss: 0.3079\n",
      "Epoch 1492/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0619 - val_loss: 0.3178\n",
      "Epoch 1493/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0595 - val_loss: 0.3365\n",
      "Epoch 1494/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0668 - val_loss: 0.3340\n",
      "Epoch 1495/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0665 - val_loss: 0.3199\n",
      "Epoch 1496/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0627 - val_loss: 0.3152\n",
      "Epoch 1497/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0617 - val_loss: 0.3153\n",
      "Epoch 1498/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0640 - val_loss: 0.3327\n",
      "Epoch 1499/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0785 - val_loss: 0.3152\n",
      "Epoch 1500/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0669 - val_loss: 0.3246\n",
      "Epoch 1501/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0811 - val_loss: 0.3205\n",
      "Epoch 1502/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0718 - val_loss: 0.3133\n",
      "Epoch 1503/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0620 - val_loss: 0.3101\n",
      "Epoch 1504/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0629 - val_loss: 0.3093\n",
      "Epoch 1505/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0588 - val_loss: 0.3126\n",
      "Epoch 1506/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0594 - val_loss: 0.3217\n",
      "Epoch 1507/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0593 - val_loss: 0.3184\n",
      "Epoch 1508/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0682 - val_loss: 0.3285\n",
      "Epoch 1509/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0845 - val_loss: 0.3180\n",
      "Epoch 1510/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0719 - val_loss: 0.3129\n",
      "Epoch 1511/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0614 - val_loss: 0.3117\n",
      "Epoch 1512/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0590 - val_loss: 0.3160\n",
      "Epoch 1513/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0611 - val_loss: 0.3168\n",
      "Epoch 1514/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0624 - val_loss: 0.3276\n",
      "Epoch 1515/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0803 - val_loss: 0.3250\n",
      "Epoch 1516/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0720 - val_loss: 0.3275\n",
      "Epoch 1517/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0624 - val_loss: 0.3154\n",
      "Epoch 1518/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0600 - val_loss: 0.3173\n",
      "Epoch 1519/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0650 - val_loss: 0.3230\n",
      "Epoch 1520/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0717 - val_loss: 0.3184\n",
      "Epoch 1521/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0640 - val_loss: 0.3231\n",
      "Epoch 1522/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0632 - val_loss: 0.3282\n",
      "Epoch 1523/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0618 - val_loss: 0.3296\n",
      "Epoch 1524/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0602 - val_loss: 0.3276\n",
      "Epoch 1525/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0662 - val_loss: 0.3452\n",
      "Epoch 1526/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0805 - val_loss: 0.3186\n",
      "Epoch 1527/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0698 - val_loss: 0.3132\n",
      "Epoch 1528/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0608 - val_loss: 0.3211\n",
      "Epoch 1529/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0621 - val_loss: 0.3137\n",
      "Epoch 1530/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0631 - val_loss: 0.3189\n",
      "Epoch 1531/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0625 - val_loss: 0.3222\n",
      "Epoch 1532/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0774 - val_loss: 0.3453\n",
      "Epoch 1533/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0671 - val_loss: 0.3226\n",
      "Epoch 1534/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0594 - val_loss: 0.3191\n",
      "Epoch 1535/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0598 - val_loss: 0.3313\n",
      "Epoch 1536/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0809 - val_loss: 0.3156\n",
      "Epoch 1537/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0840 - val_loss: 0.3163\n",
      "Epoch 1538/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0721 - val_loss: 0.3137\n",
      "Epoch 1539/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0586 - val_loss: 0.3092\n",
      "Epoch 1540/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0581 - val_loss: 0.3124\n",
      "Epoch 1541/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0604 - val_loss: 0.3163\n",
      "Epoch 1542/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0617 - val_loss: 0.3197\n",
      "Epoch 1543/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0602 - val_loss: 0.3207\n",
      "Epoch 1544/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0600 - val_loss: 0.3231\n",
      "Epoch 1545/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0782 - val_loss: 0.3160\n",
      "Epoch 1546/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0646 - val_loss: 0.3183\n",
      "Epoch 1547/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0658 - val_loss: 0.3334\n",
      "Epoch 1548/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0699 - val_loss: 0.3172\n",
      "Epoch 1549/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0609 - val_loss: 0.3167\n",
      "Epoch 1550/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0601 - val_loss: 0.3234\n",
      "Epoch 1551/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0712 - val_loss: 0.3253\n",
      "Epoch 1552/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0693 - val_loss: 0.3254\n",
      "Epoch 1553/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0613 - val_loss: 0.3190\n",
      "Epoch 1554/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0725 - val_loss: 0.3397\n",
      "Epoch 1555/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0758 - val_loss: 0.3262\n",
      "Epoch 1556/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0632 - val_loss: 0.3144\n",
      "Epoch 1557/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0634 - val_loss: 0.3194\n",
      "Epoch 1558/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0586 - val_loss: 0.3151\n",
      "Epoch 1559/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0604 - val_loss: 0.3392\n",
      "Epoch 1560/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0677 - val_loss: 0.3218\n",
      "Epoch 1561/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0664 - val_loss: 0.3214\n",
      "Epoch 1562/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0737 - val_loss: 0.3230\n",
      "Epoch 1563/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0594 - val_loss: 0.3174\n",
      "Epoch 1564/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0610 - val_loss: 0.3267\n",
      "Epoch 1565/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0618 - val_loss: 0.3234\n",
      "Epoch 1566/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0720 - val_loss: 0.3382\n",
      "Epoch 1567/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0760 - val_loss: 0.3225\n",
      "Epoch 1568/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0608 - val_loss: 0.3269\n",
      "Epoch 1569/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0602 - val_loss: 0.3298\n",
      "Epoch 1570/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0693 - val_loss: 0.3220\n",
      "Epoch 1571/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0748 - val_loss: 0.3283\n",
      "Epoch 1572/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0636 - val_loss: 0.3210\n",
      "Epoch 1573/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0591 - val_loss: 0.3206\n",
      "Epoch 1574/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0590 - val_loss: 0.3237\n",
      "Epoch 1575/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0600 - val_loss: 0.3267\n",
      "Epoch 1576/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0639 - val_loss: 0.3247\n",
      "Epoch 1577/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0720 - val_loss: 0.3389\n",
      "Epoch 1578/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0675 - val_loss: 0.3379\n",
      "Epoch 1579/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0693 - val_loss: 0.3324\n",
      "Epoch 1580/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0640 - val_loss: 0.3152\n",
      "Epoch 1581/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0611 - val_loss: 0.3302\n",
      "Epoch 1582/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0740 - val_loss: 0.3263\n",
      "Epoch 1583/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0696 - val_loss: 0.3240\n",
      "Epoch 1584/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0661 - val_loss: 0.3223\n",
      "Epoch 1585/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0626 - val_loss: 0.3202\n",
      "Epoch 1586/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0628 - val_loss: 0.3210\n",
      "Epoch 1587/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0591 - val_loss: 0.3249\n",
      "Epoch 1588/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0597 - val_loss: 0.3324\n",
      "Epoch 1589/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0732 - val_loss: 0.3341\n",
      "Epoch 1590/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0792 - val_loss: 0.3175\n",
      "Epoch 1591/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0630 - val_loss: 0.3275\n",
      "Epoch 1592/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0604 - val_loss: 0.3242\n",
      "Epoch 1593/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0605 - val_loss: 0.3299\n",
      "Epoch 1594/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0613 - val_loss: 0.3242\n",
      "Epoch 1595/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0836 - val_loss: 0.3222\n",
      "Epoch 1596/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0613 - val_loss: 0.3150\n",
      "Epoch 1597/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0582 - val_loss: 0.3247\n",
      "Epoch 1598/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0617 - val_loss: 0.3200\n",
      "Epoch 1599/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0607 - val_loss: 0.3252\n",
      "Epoch 1600/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0654 - val_loss: 0.3236\n",
      "Epoch 1601/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0666 - val_loss: 0.3236\n",
      "Epoch 1602/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0656 - val_loss: 0.3376\n",
      "Epoch 1603/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0960 - val_loss: 0.3172\n",
      "Epoch 1604/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0693 - val_loss: 0.3223\n",
      "Epoch 1605/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0597 - val_loss: 0.3118\n",
      "Epoch 1606/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0582 - val_loss: 0.3163\n",
      "Epoch 1607/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0568 - val_loss: 0.3211\n",
      "Epoch 1608/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0598 - val_loss: 0.3193\n",
      "Epoch 1609/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0599 - val_loss: 0.3232\n",
      "Epoch 1610/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0643 - val_loss: 0.3288\n",
      "Epoch 1611/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0696 - val_loss: 0.3222\n",
      "Epoch 1612/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0659 - val_loss: 0.3234\n",
      "Epoch 1613/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0646 - val_loss: 0.3288\n",
      "Epoch 1614/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0661 - val_loss: 0.3489\n",
      "Epoch 1615/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0761 - val_loss: 0.3261\n",
      "Epoch 1616/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0596 - val_loss: 0.3307\n",
      "Epoch 1617/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0643 - val_loss: 0.3217\n",
      "Epoch 1618/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0599 - val_loss: 0.3380\n",
      "Epoch 1619/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0714 - val_loss: 0.3240\n",
      "Epoch 1620/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0629 - val_loss: 0.3195\n",
      "Epoch 1621/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0654 - val_loss: 0.3309\n",
      "Epoch 1622/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0624 - val_loss: 0.3267\n",
      "Epoch 1623/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0682 - val_loss: 0.3351\n",
      "Epoch 1624/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0728 - val_loss: 0.3257\n",
      "Epoch 1625/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0624 - val_loss: 0.3240\n",
      "Epoch 1626/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0603 - val_loss: 0.3271\n",
      "Epoch 1627/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0616 - val_loss: 0.3239\n",
      "Epoch 1628/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0596 - val_loss: 0.3447\n",
      "Epoch 1629/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0655 - val_loss: 0.3319\n",
      "Epoch 1630/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0641 - val_loss: 0.3408\n",
      "Epoch 1631/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0849 - val_loss: 0.3385\n",
      "Epoch 1632/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0730 - val_loss: 0.3212\n",
      "Epoch 1633/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0615 - val_loss: 0.3199\n",
      "Epoch 1634/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0589 - val_loss: 0.3303\n",
      "Epoch 1635/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0571 - val_loss: 0.3239\n",
      "Epoch 1636/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0579 - val_loss: 0.3340\n",
      "Epoch 1637/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0927 - val_loss: 0.3269\n",
      "Epoch 1638/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0679 - val_loss: 0.3191\n",
      "Epoch 1639/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0572 - val_loss: 0.3299\n",
      "Epoch 1640/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0567 - val_loss: 0.3245\n",
      "Epoch 1641/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0564 - val_loss: 0.3341\n",
      "Epoch 1642/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0643 - val_loss: 0.3291\n",
      "Epoch 1643/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0626 - val_loss: 0.3282\n",
      "Epoch 1644/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0896 - val_loss: 0.3225\n",
      "Epoch 1645/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0609 - val_loss: 0.3191\n",
      "Epoch 1646/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0591 - val_loss: 0.3224\n",
      "Epoch 1647/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0580 - val_loss: 0.3326\n",
      "Epoch 1648/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0622 - val_loss: 0.3497\n",
      "Epoch 1649/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0823 - val_loss: 0.3354\n",
      "Epoch 1650/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0616 - val_loss: 0.3181\n",
      "Epoch 1651/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0581 - val_loss: 0.3362\n",
      "Epoch 1652/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0663 - val_loss: 0.3344\n",
      "Epoch 1653/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0619 - val_loss: 0.3217\n",
      "Epoch 1654/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0584 - val_loss: 0.3255\n",
      "Epoch 1655/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0607 - val_loss: 0.3408\n",
      "Epoch 1656/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0690 - val_loss: 0.3400\n",
      "Epoch 1657/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0699 - val_loss: 0.3367\n",
      "Epoch 1658/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.0635 - val_loss: 0.3346\n",
      "Epoch 1659/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0619 - val_loss: 0.3314\n",
      "Epoch 1660/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0590 - val_loss: 0.3317\n",
      "Epoch 1661/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0582 - val_loss: 0.3320\n",
      "Epoch 1662/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0719 - val_loss: 0.3291\n",
      "Epoch 1663/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0749 - val_loss: 0.3276\n",
      "Epoch 1664/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0612 - val_loss: 0.3260\n",
      "Epoch 1665/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0618 - val_loss: 0.3319\n",
      "Epoch 1666/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0618 - val_loss: 0.3270\n",
      "Epoch 1667/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0750 - val_loss: 0.3320\n",
      "Epoch 1668/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0652 - val_loss: 0.3250\n",
      "Epoch 1669/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0600 - val_loss: 0.3235\n",
      "Epoch 1670/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0803 - val_loss: 0.3246\n",
      "Epoch 1671/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0659 - val_loss: 0.3185\n",
      "Epoch 1672/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0572 - val_loss: 0.3287\n",
      "Epoch 1673/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0560 - val_loss: 0.3344\n",
      "Epoch 1674/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0667 - val_loss: 0.3247\n",
      "Epoch 1675/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0588 - val_loss: 0.3290\n",
      "Epoch 1676/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0592 - val_loss: 0.3507\n",
      "Epoch 1677/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0656 - val_loss: 0.3348\n",
      "Epoch 1678/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0660 - val_loss: 0.3339\n",
      "Epoch 1679/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0655 - val_loss: 0.3305\n",
      "Epoch 1680/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0665 - val_loss: 0.3403\n",
      "Epoch 1681/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0777 - val_loss: 0.3247\n",
      "Epoch 1682/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0677 - val_loss: 0.3267\n",
      "Epoch 1683/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0597 - val_loss: 0.3218\n",
      "Epoch 1684/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0587 - val_loss: 0.3332\n",
      "Epoch 1685/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0567 - val_loss: 0.3281\n",
      "Epoch 1686/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0704 - val_loss: 0.3380\n",
      "Epoch 1687/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0617 - val_loss: 0.3278\n",
      "Epoch 1688/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0593 - val_loss: 0.3341\n",
      "Epoch 1689/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0594 - val_loss: 0.3369\n",
      "Epoch 1690/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0741 - val_loss: 0.3351\n",
      "Epoch 1691/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0737 - val_loss: 0.3242\n",
      "Epoch 1692/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0630 - val_loss: 0.3256\n",
      "Epoch 1693/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0709 - val_loss: 0.3270\n",
      "Epoch 1694/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0584 - val_loss: 0.3240\n",
      "Epoch 1695/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0560 - val_loss: 0.3333\n",
      "Epoch 1696/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0605 - val_loss: 0.3386\n",
      "Epoch 1697/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0629 - val_loss: 0.3394\n",
      "Epoch 1698/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0672 - val_loss: 0.3651\n",
      "Epoch 1699/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0707 - val_loss: 0.3321\n",
      "Epoch 1700/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0640 - val_loss: 0.3275\n",
      "Epoch 1701/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0841 - val_loss: 0.3213\n",
      "Epoch 1702/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0636 - val_loss: 0.3266\n",
      "Epoch 1703/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0605 - val_loss: 0.3218\n",
      "Epoch 1704/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0577 - val_loss: 0.3281\n",
      "Epoch 1705/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0584 - val_loss: 0.3333\n",
      "Epoch 1706/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0597 - val_loss: 0.3308\n",
      "Epoch 1707/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0700 - val_loss: 0.3715\n",
      "Epoch 1708/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0725 - val_loss: 0.3346\n",
      "Epoch 1709/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0615 - val_loss: 0.3256\n",
      "Epoch 1710/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0657 - val_loss: 0.3317\n",
      "Epoch 1711/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0599 - val_loss: 0.3339\n",
      "Epoch 1712/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0572 - val_loss: 0.3299\n",
      "Epoch 1713/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0641 - val_loss: 0.3295\n",
      "Epoch 1714/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0635 - val_loss: 0.3282\n",
      "Epoch 1715/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0626 - val_loss: 0.3388\n",
      "Epoch 1716/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0690 - val_loss: 0.3307\n",
      "Epoch 1717/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0617 - val_loss: 0.3261\n",
      "Epoch 1718/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0596 - val_loss: 0.3327\n",
      "Epoch 1719/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0884 - val_loss: 0.3270\n",
      "Epoch 1720/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0603 - val_loss: 0.3243\n",
      "Epoch 1721/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0562 - val_loss: 0.3406\n",
      "Epoch 1722/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0659 - val_loss: 0.3335\n",
      "Epoch 1723/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0587 - val_loss: 0.3337\n",
      "Epoch 1724/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0609 - val_loss: 0.3475\n",
      "Epoch 1725/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0640 - val_loss: 0.3423\n",
      "Epoch 1726/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0675 - val_loss: 0.3360\n",
      "Epoch 1727/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0614 - val_loss: 0.3403\n",
      "Epoch 1728/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0651 - val_loss: 0.3393\n",
      "Epoch 1729/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0747 - val_loss: 0.3464\n",
      "Epoch 1730/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0735 - val_loss: 0.3233\n",
      "Epoch 1731/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0584 - val_loss: 0.3255\n",
      "Epoch 1732/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0557 - val_loss: 0.3250\n",
      "Epoch 1733/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0558 - val_loss: 0.3297\n",
      "Epoch 1734/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0570 - val_loss: 0.3338\n",
      "Epoch 1735/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0650 - val_loss: 0.3364\n",
      "Epoch 1736/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0787 - val_loss: 0.3422\n",
      "Epoch 1737/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0750 - val_loss: 0.3501\n",
      "Epoch 1738/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0716 - val_loss: 0.3201\n",
      "Epoch 1739/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0585 - val_loss: 0.3257\n",
      "Epoch 1740/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0552 - val_loss: 0.3300\n",
      "Epoch 1741/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0551 - val_loss: 0.3286\n",
      "Epoch 1742/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0626 - val_loss: 0.3639\n",
      "Epoch 1743/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0833 - val_loss: 0.3377\n",
      "Epoch 1744/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0703 - val_loss: 0.3244\n",
      "Epoch 1745/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0570 - val_loss: 0.3262\n",
      "Epoch 1746/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0554 - val_loss: 0.3325\n",
      "Epoch 1747/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0565 - val_loss: 0.3352\n",
      "Epoch 1748/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0599 - val_loss: 0.3286\n",
      "Epoch 1749/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0647 - val_loss: 0.3543\n",
      "Epoch 1750/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0676 - val_loss: 0.3375\n",
      "Epoch 1751/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0642 - val_loss: 0.3616\n",
      "Epoch 1752/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0734 - val_loss: 0.3338\n",
      "Epoch 1753/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0587 - val_loss: 0.3341\n",
      "Epoch 1754/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0562 - val_loss: 0.3279\n",
      "Epoch 1755/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0580 - val_loss: 0.3345\n",
      "Epoch 1756/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0650 - val_loss: 0.3389\n",
      "Epoch 1757/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0710 - val_loss: 0.3483\n",
      "Epoch 1758/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0695 - val_loss: 0.3345\n",
      "Epoch 1759/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0827 - val_loss: 0.3302\n",
      "Epoch 1760/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0607 - val_loss: 0.3262\n",
      "Epoch 1761/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0556 - val_loss: 0.3260\n",
      "Epoch 1762/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0561 - val_loss: 0.3327\n",
      "Epoch 1763/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0580 - val_loss: 0.3297\n",
      "Epoch 1764/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0592 - val_loss: 0.3334\n",
      "Epoch 1765/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0694 - val_loss: 0.3447\n",
      "Epoch 1766/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0644 - val_loss: 0.3382\n",
      "Epoch 1767/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0604 - val_loss: 0.3318\n",
      "Epoch 1768/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0677 - val_loss: 0.4419\n",
      "Epoch 1769/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0970 - val_loss: 0.3199\n",
      "Epoch 1770/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0589 - val_loss: 0.3225\n",
      "Epoch 1771/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0556 - val_loss: 0.3305\n",
      "Epoch 1772/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0556 - val_loss: 0.3284\n",
      "Epoch 1773/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0582 - val_loss: 0.3429\n",
      "Epoch 1774/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0594 - val_loss: 0.3389\n",
      "Epoch 1775/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0692 - val_loss: 0.3393\n",
      "Epoch 1776/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0673 - val_loss: 0.3273\n",
      "Epoch 1777/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0588 - val_loss: 0.3360\n",
      "Epoch 1778/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0585 - val_loss: 0.3319\n",
      "Epoch 1779/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0594 - val_loss: 0.3372\n",
      "Epoch 1780/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0843 - val_loss: 0.3587\n",
      "Epoch 1781/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0887 - val_loss: 0.3260\n",
      "Epoch 1782/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0598 - val_loss: 0.3207\n",
      "Epoch 1783/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0543 - val_loss: 0.3242\n",
      "Epoch 1784/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0556 - val_loss: 0.3462\n",
      "Epoch 1785/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0564 - val_loss: 0.3353\n",
      "Epoch 1786/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0569 - val_loss: 0.3420\n",
      "Epoch 1787/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0572 - val_loss: 0.3336\n",
      "Epoch 1788/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0673 - val_loss: 0.3349\n",
      "Epoch 1789/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0655 - val_loss: 0.3470\n",
      "Epoch 1790/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0728 - val_loss: 0.3309\n",
      "Epoch 1791/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0616 - val_loss: 0.3332\n",
      "Epoch 1792/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0587 - val_loss: 0.3316\n",
      "Epoch 1793/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0576 - val_loss: 0.3335\n",
      "Epoch 1794/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0634 - val_loss: 0.3401\n",
      "Epoch 1795/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.0602 - val_loss: 0.3417\n",
      "Epoch 1796/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0620 - val_loss: 0.3565\n",
      "Epoch 1797/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0614 - val_loss: 0.3325\n",
      "Epoch 1798/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0663 - val_loss: 0.3496\n",
      "Epoch 1799/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0665 - val_loss: 0.3353\n",
      "Epoch 1800/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0672 - val_loss: 0.3345\n",
      "Epoch 1801/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0599 - val_loss: 0.3334\n",
      "Epoch 1802/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0600 - val_loss: 0.3355\n",
      "Epoch 1803/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0613 - val_loss: 0.3458\n",
      "Epoch 1804/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0832 - val_loss: 0.3329\n",
      "Epoch 1805/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0635 - val_loss: 0.3248\n",
      "Epoch 1806/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0573 - val_loss: 0.3367\n",
      "Epoch 1807/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0592 - val_loss: 0.3320\n",
      "Epoch 1808/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0585 - val_loss: 0.3395\n",
      "Epoch 1809/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0744 - val_loss: 0.3386\n",
      "Epoch 1810/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0638 - val_loss: 0.3369\n",
      "Epoch 1811/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0619 - val_loss: 0.3340\n",
      "Epoch 1812/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0604 - val_loss: 0.3357\n",
      "Epoch 1813/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0586 - val_loss: 0.3378\n",
      "Epoch 1814/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0660 - val_loss: 0.3453\n",
      "Epoch 1815/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0658 - val_loss: 0.3300\n",
      "Epoch 1816/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0566 - val_loss: 0.3334\n",
      "Epoch 1817/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0652 - val_loss: 0.3365\n",
      "Epoch 1818/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0663 - val_loss: 0.3329\n",
      "Epoch 1819/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0645 - val_loss: 0.3459\n",
      "Epoch 1820/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0592 - val_loss: 0.3337\n",
      "Epoch 1821/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0565 - val_loss: 0.3452\n",
      "Epoch 1822/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0720 - val_loss: 0.3393\n",
      "Epoch 1823/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0664 - val_loss: 0.3322\n",
      "Epoch 1824/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0599 - val_loss: 0.3328\n",
      "Epoch 1825/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0646 - val_loss: 0.3523\n",
      "Epoch 1826/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0795 - val_loss: 0.3323\n",
      "Epoch 1827/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0585 - val_loss: 0.3326\n",
      "Epoch 1828/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0547 - val_loss: 0.3325\n",
      "Epoch 1829/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0551 - val_loss: 0.3322\n",
      "Epoch 1830/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0597 - val_loss: 0.3488\n",
      "Epoch 1831/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0630 - val_loss: 0.3410\n",
      "Epoch 1832/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0585 - val_loss: 0.3481\n",
      "Epoch 1833/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0779 - val_loss: 0.3329\n",
      "Epoch 1834/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0605 - val_loss: 0.3357\n",
      "Epoch 1835/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0611 - val_loss: 0.3370\n",
      "Epoch 1836/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0757 - val_loss: 0.3547\n",
      "Epoch 1837/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0705 - val_loss: 0.3230\n",
      "Epoch 1838/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0577 - val_loss: 0.3313\n",
      "Epoch 1839/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0549 - val_loss: 0.3320\n",
      "Epoch 1840/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0548 - val_loss: 0.3359\n",
      "Epoch 1841/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0578 - val_loss: 0.3403\n",
      "Epoch 1842/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0664 - val_loss: 0.3385\n",
      "Epoch 1843/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0641 - val_loss: 0.3450\n",
      "Epoch 1844/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0588 - val_loss: 0.3391\n",
      "Epoch 1845/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0750 - val_loss: 0.3381\n",
      "Epoch 1846/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0689 - val_loss: 0.3310\n",
      "Epoch 1847/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0593 - val_loss: 0.3322\n",
      "Epoch 1848/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0589 - val_loss: 0.3365\n",
      "Epoch 1849/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0574 - val_loss: 0.3324\n",
      "Epoch 1850/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0703 - val_loss: 0.3387\n",
      "Epoch 1851/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0684 - val_loss: 0.3376\n",
      "Epoch 1852/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0637 - val_loss: 0.3614\n",
      "Epoch 1853/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0681 - val_loss: 0.3340\n",
      "Epoch 1854/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0552 - val_loss: 0.3303\n",
      "Epoch 1855/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0566 - val_loss: 0.3392\n",
      "Epoch 1856/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0565 - val_loss: 0.3421\n",
      "Epoch 1857/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0632 - val_loss: 0.3814\n",
      "Epoch 1858/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0899 - val_loss: 0.3312\n",
      "Epoch 1859/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0618 - val_loss: 0.3408\n",
      "Epoch 1860/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0574 - val_loss: 0.3336\n",
      "Epoch 1861/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0566 - val_loss: 0.3340\n",
      "Epoch 1862/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0549 - val_loss: 0.3336\n",
      "Epoch 1863/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0550 - val_loss: 0.3434\n",
      "Epoch 1864/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0635 - val_loss: 0.3536\n",
      "Epoch 1865/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0677 - val_loss: 0.3332\n",
      "Epoch 1866/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0663 - val_loss: 0.3452\n",
      "Epoch 1867/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0691 - val_loss: 0.3453\n",
      "Epoch 1868/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0618 - val_loss: 0.3387\n",
      "Epoch 1869/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0582 - val_loss: 0.3392\n",
      "Epoch 1870/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0565 - val_loss: 0.3485\n",
      "Epoch 1871/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0661 - val_loss: 0.3376\n",
      "Epoch 1872/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0603 - val_loss: 0.3443\n",
      "Epoch 1873/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0713 - val_loss: 0.3416\n",
      "Epoch 1874/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0633 - val_loss: 0.4192\n",
      "Epoch 1875/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0702 - val_loss: 0.3319\n",
      "Epoch 1876/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0746 - val_loss: 0.3419\n",
      "Epoch 1877/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0554 - val_loss: 0.3360\n",
      "Epoch 1878/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0535 - val_loss: 0.3330\n",
      "Epoch 1879/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0534 - val_loss: 0.3373\n",
      "Epoch 1880/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0559 - val_loss: 0.3399\n",
      "Epoch 1881/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0618 - val_loss: 0.3424\n",
      "Epoch 1882/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0609 - val_loss: 0.3398\n",
      "Epoch 1883/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0582 - val_loss: 0.3526\n",
      "Epoch 1884/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0619 - val_loss: 0.3498\n",
      "Epoch 1885/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0866 - val_loss: 0.3636\n",
      "Epoch 1886/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0737 - val_loss: 0.3432\n",
      "Epoch 1887/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0592 - val_loss: 0.3306\n",
      "Epoch 1888/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0531 - val_loss: 0.3348\n",
      "Epoch 1889/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0543 - val_loss: 0.3423\n",
      "Epoch 1890/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0851 - val_loss: 0.3336\n",
      "Epoch 1891/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0684 - val_loss: 0.3325\n",
      "Epoch 1892/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0566 - val_loss: 0.3338\n",
      "Epoch 1893/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0563 - val_loss: 0.3328\n",
      "Epoch 1894/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0553 - val_loss: 0.3413\n",
      "Epoch 1895/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0561 - val_loss: 0.3465\n",
      "Epoch 1896/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0643 - val_loss: 0.3487\n",
      "Epoch 1897/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0746 - val_loss: 0.3399\n",
      "Epoch 1898/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0593 - val_loss: 0.3335\n",
      "Epoch 1899/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0571 - val_loss: 0.3374\n",
      "Epoch 1900/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0632 - val_loss: 0.3543\n",
      "Epoch 1901/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0614 - val_loss: 0.3448\n",
      "Epoch 1902/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0592 - val_loss: 0.3622\n",
      "Epoch 1903/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0619 - val_loss: 0.3402\n",
      "Epoch 1904/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0638 - val_loss: 0.3430\n",
      "Epoch 1905/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0696 - val_loss: 0.3723\n",
      "Epoch 1906/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0708 - val_loss: 0.3409\n",
      "Epoch 1907/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0588 - val_loss: 0.3439\n",
      "Epoch 1908/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0557 - val_loss: 0.3376\n",
      "Epoch 1909/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0670 - val_loss: 0.3970\n",
      "Epoch 1910/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0876 - val_loss: 0.3299\n",
      "Epoch 1911/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0581 - val_loss: 0.3314\n",
      "Epoch 1912/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0552 - val_loss: 0.3339\n",
      "Epoch 1913/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0537 - val_loss: 0.3373\n",
      "Epoch 1914/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0529 - val_loss: 0.3371\n",
      "Epoch 1915/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0551 - val_loss: 0.3427\n",
      "Epoch 1916/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0751 - val_loss: 0.3565\n",
      "Epoch 1917/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0692 - val_loss: 0.3398\n",
      "Epoch 1918/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0674 - val_loss: 0.3421\n",
      "Epoch 1919/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0674 - val_loss: 0.3293\n",
      "Epoch 1920/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0545 - val_loss: 0.3332\n",
      "Epoch 1921/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0547 - val_loss: 0.3422\n",
      "Epoch 1922/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0569 - val_loss: 0.3503\n",
      "Epoch 1923/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0707 - val_loss: 0.3480\n",
      "Epoch 1924/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0624 - val_loss: 0.3317\n",
      "Epoch 1925/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0546 - val_loss: 0.3359\n",
      "Epoch 1926/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0579 - val_loss: 0.3400\n",
      "Epoch 1927/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0611 - val_loss: 0.4531\n",
      "Epoch 1928/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0857 - val_loss: 0.3380\n",
      "Epoch 1929/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0642 - val_loss: 0.3396\n",
      "Epoch 1930/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0557 - val_loss: 0.3349\n",
      "Epoch 1931/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0546 - val_loss: 0.3457\n",
      "Epoch 1932/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0550 - val_loss: 0.3404\n",
      "Epoch 1933/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0604 - val_loss: 0.3424\n",
      "Epoch 1934/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0671 - val_loss: 0.3585\n",
      "Epoch 1935/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0791 - val_loss: 0.3368\n",
      "Epoch 1936/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0585 - val_loss: 0.3355\n",
      "Epoch 1937/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0565 - val_loss: 0.3402\n",
      "Epoch 1938/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0635 - val_loss: 0.3339\n",
      "Epoch 1939/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0571 - val_loss: 0.3374\n",
      "Epoch 1940/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0681 - val_loss: 0.3578\n",
      "Epoch 1941/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0808 - val_loss: 0.3308\n",
      "Epoch 1942/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0569 - val_loss: 0.3387\n",
      "Epoch 1943/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0551 - val_loss: 0.3413\n",
      "Epoch 1944/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0557 - val_loss: 0.3422\n",
      "Epoch 1945/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0551 - val_loss: 0.3385\n",
      "Epoch 1946/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0637 - val_loss: 0.3543\n",
      "Epoch 1947/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0775 - val_loss: 0.3340\n",
      "Epoch 1948/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0597 - val_loss: 0.3357\n",
      "Epoch 1949/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0560 - val_loss: 0.3374\n",
      "Epoch 1950/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0560 - val_loss: 0.3417\n",
      "Epoch 1951/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0551 - val_loss: 0.3490\n",
      "Epoch 1952/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0734 - val_loss: 0.3474\n",
      "Epoch 1953/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0613 - val_loss: 0.3434\n",
      "Epoch 1954/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0575 - val_loss: 0.3404\n",
      "Epoch 1955/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0612 - val_loss: 0.3531\n",
      "Epoch 1956/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0607 - val_loss: 0.3502\n",
      "Epoch 1957/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0621 - val_loss: 0.3492\n",
      "Epoch 1958/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0692 - val_loss: 0.3519\n",
      "Epoch 1959/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0598 - val_loss: 0.3406\n",
      "Epoch 1960/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0581 - val_loss: 0.3470\n",
      "Epoch 1961/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0660 - val_loss: 0.3514\n",
      "Epoch 1962/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0625 - val_loss: 0.3491\n",
      "Epoch 1963/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0624 - val_loss: 0.3528\n",
      "Epoch 1964/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0579 - val_loss: 0.3463\n",
      "Epoch 1965/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0554 - val_loss: 0.3510\n",
      "Epoch 1966/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.0788 - val_loss: 0.3515\n",
      "Epoch 1967/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0648 - val_loss: 0.3405\n",
      "Epoch 1968/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0554 - val_loss: 0.3392\n",
      "Epoch 1969/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0552 - val_loss: 0.3477\n",
      "Epoch 1970/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0614 - val_loss: 0.3412\n",
      "Epoch 1971/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.0595 - val_loss: 0.3528\n",
      "Epoch 1972/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0731 - val_loss: 0.3449\n",
      "Epoch 1973/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0631 - val_loss: 0.3469\n",
      "Epoch 1974/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0566 - val_loss: 0.3397\n",
      "Epoch 1975/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0577 - val_loss: 0.3428\n",
      "Epoch 1976/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0569 - val_loss: 0.3471\n",
      "Epoch 1977/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0575 - val_loss: 0.3398\n",
      "Epoch 1978/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0598 - val_loss: 0.3481\n",
      "Epoch 1979/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0756 - val_loss: 0.3676\n",
      "Epoch 1980/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0761 - val_loss: 0.3370\n",
      "Epoch 1981/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0631 - val_loss: 0.3662\n",
      "Epoch 1982/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0592 - val_loss: 0.3568\n",
      "Epoch 1983/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0606 - val_loss: 0.3357\n",
      "Epoch 1984/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0566 - val_loss: 0.3406\n",
      "Epoch 1985/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0529 - val_loss: 0.3458\n",
      "Epoch 1986/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0580 - val_loss: 0.3558\n",
      "Epoch 1987/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0614 - val_loss: 0.3455\n",
      "Epoch 1988/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0764 - val_loss: 0.3649\n",
      "Epoch 1989/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0646 - val_loss: 0.3399\n",
      "Epoch 1990/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0561 - val_loss: 0.3397\n",
      "Epoch 1991/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.0540 - val_loss: 0.3413\n",
      "Epoch 1992/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0569 - val_loss: 0.3537\n",
      "Epoch 1993/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0600 - val_loss: 0.3454\n",
      "Epoch 1994/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0920 - val_loss: 0.3703\n",
      "Epoch 1995/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.0713 - val_loss: 0.3367\n",
      "Epoch 1996/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0569 - val_loss: 0.3412\n",
      "Epoch 1997/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0541 - val_loss: 0.3416\n",
      "Epoch 1998/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.0543 - val_loss: 0.3387\n",
      "Epoch 1999/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0539 - val_loss: 0.3429\n",
      "Epoch 2000/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.0670 - val_loss: 0.3593\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10, 10, 7)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 12, 12, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 12, 12, 128)       8192      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 64)          73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 3, 32)          18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1, 1, 16)          528       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1, 1, 16)          0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1, 1, 32)          544       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 3, 64)          18496     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 10, 10, 7)         8071      \n",
      "_________________________________________________________________\n",
      "softmax_2 (Softmax)          (None, 10, 10, 7)         0         \n",
      "=================================================================\n",
      "Total params: 201,943\n",
      "Trainable params: 201,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15000 samples, validate on 2584 samples\n",
      "Epoch 1/2000\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.6055 - val_loss: 0.4136\n",
      "Epoch 2/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.3943 - val_loss: 0.3840\n",
      "Epoch 3/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.3644 - val_loss: 0.3584\n",
      "Epoch 4/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.3473 - val_loss: 0.3548\n",
      "Epoch 5/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3384 - val_loss: 0.3383\n",
      "Epoch 6/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3307 - val_loss: 0.3322\n",
      "Epoch 7/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3244 - val_loss: 0.3376\n",
      "Epoch 8/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3191 - val_loss: 0.3210\n",
      "Epoch 9/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.3089 - val_loss: 0.3187\n",
      "Epoch 10/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.3034 - val_loss: 0.3113\n",
      "Epoch 11/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.3019 - val_loss: 0.3061\n",
      "Epoch 12/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.3003 - val_loss: 0.3070\n",
      "Epoch 13/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2982 - val_loss: 0.3066\n",
      "Epoch 14/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2961 - val_loss: 0.3009\n",
      "Epoch 15/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2940 - val_loss: 0.3009\n",
      "Epoch 16/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2938 - val_loss: 0.3019\n",
      "Epoch 17/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2914 - val_loss: 0.2986\n",
      "Epoch 18/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2902 - val_loss: 0.3001\n",
      "Epoch 19/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2892 - val_loss: 0.2975\n",
      "Epoch 20/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2885 - val_loss: 0.2948\n",
      "Epoch 21/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2865 - val_loss: 0.2967\n",
      "Epoch 22/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2862 - val_loss: 0.2939\n",
      "Epoch 23/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2841 - val_loss: 0.2978\n",
      "Epoch 24/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2848 - val_loss: 0.2997\n",
      "Epoch 25/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2831 - val_loss: 0.2923\n",
      "Epoch 26/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2811 - val_loss: 0.2903\n",
      "Epoch 27/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2816 - val_loss: 0.2928\n",
      "Epoch 28/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2798 - val_loss: 0.2911\n",
      "Epoch 29/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2788 - val_loss: 0.2913\n",
      "Epoch 30/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2776 - val_loss: 0.2959\n",
      "Epoch 31/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2769 - val_loss: 0.2904\n",
      "Epoch 32/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2729 - val_loss: 0.2820\n",
      "Epoch 33/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2684 - val_loss: 0.2773\n",
      "Epoch 34/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2644 - val_loss: 0.2759\n",
      "Epoch 35/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2627 - val_loss: 0.2747\n",
      "Epoch 36/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2594 - val_loss: 0.2710\n",
      "Epoch 37/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2590 - val_loss: 0.2671\n",
      "Epoch 38/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2564 - val_loss: 0.2714\n",
      "Epoch 39/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2558 - val_loss: 0.2660\n",
      "Epoch 40/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2535 - val_loss: 0.2675\n",
      "Epoch 41/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2516 - val_loss: 0.2689\n",
      "Epoch 42/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2513 - val_loss: 0.2651\n",
      "Epoch 43/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2504 - val_loss: 0.2621\n",
      "Epoch 44/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2489 - val_loss: 0.2633\n",
      "Epoch 45/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2476 - val_loss: 0.2606\n",
      "Epoch 46/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2503 - val_loss: 0.2661\n",
      "Epoch 47/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2466 - val_loss: 0.2604\n",
      "Epoch 48/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2451 - val_loss: 0.2645\n",
      "Epoch 49/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2437 - val_loss: 0.2668\n",
      "Epoch 50/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2460 - val_loss: 0.2640\n",
      "Epoch 51/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2442 - val_loss: 0.2616\n",
      "Epoch 52/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2408 - val_loss: 0.2604\n",
      "Epoch 53/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2399 - val_loss: 0.2656\n",
      "Epoch 54/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2390 - val_loss: 0.2619\n",
      "Epoch 55/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2396 - val_loss: 0.2574\n",
      "Epoch 56/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2400 - val_loss: 0.2557\n",
      "Epoch 57/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2369 - val_loss: 0.2546\n",
      "Epoch 58/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2369 - val_loss: 0.2630\n",
      "Epoch 59/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2375 - val_loss: 0.2561\n",
      "Epoch 60/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2356 - val_loss: 0.2555\n",
      "Epoch 61/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2383 - val_loss: 0.2619\n",
      "Epoch 62/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2345 - val_loss: 0.2546\n",
      "Epoch 63/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2331 - val_loss: 0.2590\n",
      "Epoch 64/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2345 - val_loss: 0.2683\n",
      "Epoch 65/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2349 - val_loss: 0.2562\n",
      "Epoch 66/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2334 - val_loss: 0.2536\n",
      "Epoch 67/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2313 - val_loss: 0.2538\n",
      "Epoch 68/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2313 - val_loss: 0.2547\n",
      "Epoch 69/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2336 - val_loss: 0.2514\n",
      "Epoch 70/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2289 - val_loss: 0.2547\n",
      "Epoch 71/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2291 - val_loss: 0.2570\n",
      "Epoch 72/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2288 - val_loss: 0.2504\n",
      "Epoch 73/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2294 - val_loss: 0.2552\n",
      "Epoch 74/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2286 - val_loss: 0.2497\n",
      "Epoch 75/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2291 - val_loss: 0.2509\n",
      "Epoch 76/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2276 - val_loss: 0.2500\n",
      "Epoch 77/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2268 - val_loss: 0.2531\n",
      "Epoch 78/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.2257 - val_loss: 0.2486\n",
      "Epoch 79/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2252 - val_loss: 0.2509\n",
      "Epoch 80/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2318 - val_loss: 0.2544\n",
      "Epoch 81/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2246 - val_loss: 0.2519\n",
      "Epoch 82/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2232 - val_loss: 0.2548\n",
      "Epoch 83/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2242 - val_loss: 0.2512\n",
      "Epoch 84/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2239 - val_loss: 0.2527\n",
      "Epoch 85/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2236 - val_loss: 0.2620\n",
      "Epoch 86/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2246 - val_loss: 0.2514\n",
      "Epoch 87/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2224 - val_loss: 0.2506\n",
      "Epoch 88/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2225 - val_loss: 0.2518\n",
      "Epoch 89/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2233 - val_loss: 0.2520\n",
      "Epoch 90/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2227 - val_loss: 0.2481\n",
      "Epoch 91/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2200 - val_loss: 0.2530\n",
      "Epoch 92/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2201 - val_loss: 0.2503\n",
      "Epoch 93/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2208 - val_loss: 0.2533\n",
      "Epoch 94/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2198 - val_loss: 0.2505\n",
      "Epoch 95/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2217 - val_loss: 0.2660\n",
      "Epoch 96/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2208 - val_loss: 0.2473\n",
      "Epoch 97/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2184 - val_loss: 0.2499\n",
      "Epoch 98/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2194 - val_loss: 0.2495\n",
      "Epoch 99/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2177 - val_loss: 0.2478\n",
      "Epoch 100/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2163 - val_loss: 0.2508\n",
      "Epoch 101/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2168 - val_loss: 0.2539\n",
      "Epoch 102/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2208 - val_loss: 0.2501\n",
      "Epoch 103/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2207 - val_loss: 0.2497\n",
      "Epoch 104/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2152 - val_loss: 0.2516\n",
      "Epoch 105/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2167 - val_loss: 0.2498\n",
      "Epoch 106/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2205 - val_loss: 0.2544\n",
      "Epoch 107/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2147 - val_loss: 0.2509\n",
      "Epoch 108/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2157 - val_loss: 0.2490\n",
      "Epoch 109/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2163 - val_loss: 0.2485\n",
      "Epoch 110/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2133 - val_loss: 0.2456\n",
      "Epoch 111/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2147 - val_loss: 0.2470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2128 - val_loss: 0.2549\n",
      "Epoch 113/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2199 - val_loss: 0.2446\n",
      "Epoch 114/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2114 - val_loss: 0.2507\n",
      "Epoch 115/2000\n",
      "15000/15000 [==============================] - 1s 73us/step - loss: 0.2128 - val_loss: 0.2495\n",
      "Epoch 116/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2116 - val_loss: 0.2477\n",
      "Epoch 117/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2111 - val_loss: 0.2496\n",
      "Epoch 118/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2115 - val_loss: 0.2480\n",
      "Epoch 119/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2124 - val_loss: 0.2477\n",
      "Epoch 120/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2132 - val_loss: 0.2470\n",
      "Epoch 121/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2110 - val_loss: 0.2463\n",
      "Epoch 122/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2145 - val_loss: 0.2507\n",
      "Epoch 123/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2104 - val_loss: 0.2480\n",
      "Epoch 124/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2102 - val_loss: 0.2476\n",
      "Epoch 125/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2084 - val_loss: 0.2543\n",
      "Epoch 126/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2089 - val_loss: 0.2468\n",
      "Epoch 127/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2094 - val_loss: 0.2511\n",
      "Epoch 128/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2107 - val_loss: 0.2443\n",
      "Epoch 129/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2101 - val_loss: 0.2458\n",
      "Epoch 130/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2080 - val_loss: 0.2567\n",
      "Epoch 131/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2092 - val_loss: 0.2473\n",
      "Epoch 132/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2090 - val_loss: 0.2521\n",
      "Epoch 133/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2073 - val_loss: 0.2466\n",
      "Epoch 134/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2078 - val_loss: 0.2492\n",
      "Epoch 135/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2066 - val_loss: 0.2503\n",
      "Epoch 136/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2055 - val_loss: 0.2590\n",
      "Epoch 137/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2072 - val_loss: 0.2479\n",
      "Epoch 138/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2075 - val_loss: 0.2498\n",
      "Epoch 139/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2062 - val_loss: 0.2433\n",
      "Epoch 140/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2040 - val_loss: 0.2448\n",
      "Epoch 141/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2041 - val_loss: 0.2508\n",
      "Epoch 142/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2057 - val_loss: 0.2541\n",
      "Epoch 143/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2098 - val_loss: 0.2492\n",
      "Epoch 144/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2037 - val_loss: 0.2462\n",
      "Epoch 145/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2023 - val_loss: 0.2670\n",
      "Epoch 146/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2059 - val_loss: 0.2520\n",
      "Epoch 147/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2047 - val_loss: 0.2461\n",
      "Epoch 148/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2035 - val_loss: 0.2460\n",
      "Epoch 149/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2041 - val_loss: 0.2471\n",
      "Epoch 150/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2055 - val_loss: 0.2470\n",
      "Epoch 151/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2038 - val_loss: 0.2508\n",
      "Epoch 152/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2026 - val_loss: 0.2513\n",
      "Epoch 153/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2020 - val_loss: 0.2555\n",
      "Epoch 154/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.2019 - val_loss: 0.2453\n",
      "Epoch 155/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2018 - val_loss: 0.2502\n",
      "Epoch 156/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2020 - val_loss: 0.2468\n",
      "Epoch 157/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2015 - val_loss: 0.2451\n",
      "Epoch 158/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1995 - val_loss: 0.2466\n",
      "Epoch 159/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.2002 - val_loss: 0.2462\n",
      "Epoch 160/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.2037 - val_loss: 0.2944\n",
      "Epoch 161/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2120 - val_loss: 0.2429\n",
      "Epoch 162/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1982 - val_loss: 0.2443\n",
      "Epoch 163/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1981 - val_loss: 0.2513\n",
      "Epoch 164/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.2015 - val_loss: 0.2621\n",
      "Epoch 165/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2035 - val_loss: 0.2422\n",
      "Epoch 166/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1983 - val_loss: 0.2484\n",
      "Epoch 167/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1981 - val_loss: 0.2463\n",
      "Epoch 168/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1971 - val_loss: 0.2441\n",
      "Epoch 169/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1968 - val_loss: 0.2465\n",
      "Epoch 170/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.2005 - val_loss: 0.2488\n",
      "Epoch 171/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1979 - val_loss: 0.2487\n",
      "Epoch 172/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.2050 - val_loss: 0.2458\n",
      "Epoch 173/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1966 - val_loss: 0.2474\n",
      "Epoch 174/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1964 - val_loss: 0.2469\n",
      "Epoch 175/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1982 - val_loss: 0.2477\n",
      "Epoch 176/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1968 - val_loss: 0.2497\n",
      "Epoch 177/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2003 - val_loss: 0.2485\n",
      "Epoch 178/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1960 - val_loss: 0.2447\n",
      "Epoch 179/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1964 - val_loss: 0.2491\n",
      "Epoch 180/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1968 - val_loss: 0.2464\n",
      "Epoch 181/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1962 - val_loss: 0.2511\n",
      "Epoch 182/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1958 - val_loss: 0.2518\n",
      "Epoch 183/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1949 - val_loss: 0.2466\n",
      "Epoch 184/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.2073 - val_loss: 0.2511\n",
      "Epoch 185/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1954 - val_loss: 0.2487\n",
      "Epoch 186/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1950 - val_loss: 0.2490\n",
      "Epoch 187/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1932 - val_loss: 0.2443\n",
      "Epoch 188/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1945 - val_loss: 0.2458\n",
      "Epoch 189/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1939 - val_loss: 0.2489\n",
      "Epoch 190/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1953 - val_loss: 0.2483\n",
      "Epoch 191/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1952 - val_loss: 0.2471\n",
      "Epoch 192/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1981 - val_loss: 0.2478\n",
      "Epoch 193/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1928 - val_loss: 0.2467\n",
      "Epoch 194/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1926 - val_loss: 0.2501\n",
      "Epoch 195/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1936 - val_loss: 0.2518\n",
      "Epoch 196/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1934 - val_loss: 0.2686\n",
      "Epoch 197/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1970 - val_loss: 0.2471\n",
      "Epoch 198/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1945 - val_loss: 0.2456\n",
      "Epoch 199/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1920 - val_loss: 0.2571\n",
      "Epoch 200/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1966 - val_loss: 0.2483\n",
      "Epoch 201/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1924 - val_loss: 0.2467\n",
      "Epoch 202/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1913 - val_loss: 0.2499\n",
      "Epoch 203/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1935 - val_loss: 0.2514\n",
      "Epoch 204/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1930 - val_loss: 0.2602\n",
      "Epoch 205/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1998 - val_loss: 0.2514\n",
      "Epoch 206/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1905 - val_loss: 0.2487\n",
      "Epoch 207/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1908 - val_loss: 0.2486\n",
      "Epoch 208/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1906 - val_loss: 0.2465\n",
      "Epoch 209/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1911 - val_loss: 0.2465\n",
      "Epoch 210/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1923 - val_loss: 0.2493\n",
      "Epoch 211/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1902 - val_loss: 0.2501\n",
      "Epoch 212/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1911 - val_loss: 0.2478\n",
      "Epoch 213/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1915 - val_loss: 0.2577\n",
      "Epoch 214/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1932 - val_loss: 0.2469\n",
      "Epoch 215/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1902 - val_loss: 0.2485\n",
      "Epoch 216/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1894 - val_loss: 0.2523\n",
      "Epoch 217/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1935 - val_loss: 0.2617\n",
      "Epoch 218/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1922 - val_loss: 0.2524\n",
      "Epoch 219/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1887 - val_loss: 0.2508\n",
      "Epoch 220/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1901 - val_loss: 0.2465\n",
      "Epoch 221/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1987 - val_loss: 0.2464\n",
      "Epoch 222/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1892 - val_loss: 0.2491\n",
      "Epoch 223/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1887 - val_loss: 0.2514\n",
      "Epoch 224/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1885 - val_loss: 0.2478\n",
      "Epoch 225/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1889 - val_loss: 0.2581\n",
      "Epoch 226/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1911 - val_loss: 0.2473\n",
      "Epoch 227/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1897 - val_loss: 0.2477\n",
      "Epoch 228/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1900 - val_loss: 0.2525\n",
      "Epoch 229/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1899 - val_loss: 0.2517\n",
      "Epoch 230/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1898 - val_loss: 0.2508\n",
      "Epoch 231/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1868 - val_loss: 0.2508\n",
      "Epoch 232/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1872 - val_loss: 0.2488\n",
      "Epoch 233/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1882 - val_loss: 0.2526\n",
      "Epoch 234/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1880 - val_loss: 0.2587\n",
      "Epoch 235/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1877 - val_loss: 0.2524\n",
      "Epoch 236/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1874 - val_loss: 0.2612\n",
      "Epoch 237/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1890 - val_loss: 0.2595\n",
      "Epoch 238/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1896 - val_loss: 0.2504\n",
      "Epoch 239/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1882 - val_loss: 0.2518\n",
      "Epoch 240/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1882 - val_loss: 0.2610\n",
      "Epoch 241/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1898 - val_loss: 0.2513\n",
      "Epoch 242/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1867 - val_loss: 0.2495\n",
      "Epoch 243/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1850 - val_loss: 0.2510\n",
      "Epoch 244/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1901 - val_loss: 0.2611\n",
      "Epoch 245/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1873 - val_loss: 0.2493\n",
      "Epoch 246/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1922 - val_loss: 0.2556\n",
      "Epoch 247/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1852 - val_loss: 0.2518\n",
      "Epoch 248/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1843 - val_loss: 0.2577\n",
      "Epoch 249/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1863 - val_loss: 0.2581\n",
      "Epoch 250/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1871 - val_loss: 0.2477\n",
      "Epoch 251/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1886 - val_loss: 0.2559\n",
      "Epoch 252/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1894 - val_loss: 0.2542\n",
      "Epoch 253/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1843 - val_loss: 0.2539\n",
      "Epoch 254/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1844 - val_loss: 0.2507\n",
      "Epoch 255/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1841 - val_loss: 0.2563\n",
      "Epoch 256/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1843 - val_loss: 0.2516\n",
      "Epoch 257/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1841 - val_loss: 0.2584\n",
      "Epoch 258/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1856 - val_loss: 0.2511\n",
      "Epoch 259/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1849 - val_loss: 0.2529\n",
      "Epoch 260/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1843 - val_loss: 0.2609\n",
      "Epoch 261/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1919 - val_loss: 0.2520\n",
      "Epoch 262/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1824 - val_loss: 0.2521\n",
      "Epoch 263/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1838 - val_loss: 0.2497\n",
      "Epoch 264/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1826 - val_loss: 0.2606\n",
      "Epoch 265/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1836 - val_loss: 0.2645\n",
      "Epoch 266/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1866 - val_loss: 0.2588\n",
      "Epoch 267/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1895 - val_loss: 0.2585\n",
      "Epoch 268/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1846 - val_loss: 0.2527\n",
      "Epoch 269/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1846 - val_loss: 0.2524\n",
      "Epoch 270/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1829 - val_loss: 0.2566\n",
      "Epoch 271/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1839 - val_loss: 0.2556\n",
      "Epoch 272/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1826 - val_loss: 0.2510\n",
      "Epoch 273/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1821 - val_loss: 0.2600\n",
      "Epoch 274/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1841 - val_loss: 0.2601\n",
      "Epoch 275/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1847 - val_loss: 0.2536\n",
      "Epoch 276/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1826 - val_loss: 0.2582\n",
      "Epoch 277/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1867 - val_loss: 0.2594\n",
      "Epoch 278/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1838 - val_loss: 0.2539\n",
      "Epoch 279/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1888 - val_loss: 0.2565\n",
      "Epoch 280/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1828 - val_loss: 0.2553\n",
      "Epoch 281/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1827 - val_loss: 0.2743\n",
      "Epoch 282/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1900 - val_loss: 0.2557\n",
      "Epoch 283/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1810 - val_loss: 0.2524\n",
      "Epoch 284/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1805 - val_loss: 0.2530\n",
      "Epoch 285/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1792 - val_loss: 0.2551\n",
      "Epoch 286/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1804 - val_loss: 0.2547\n",
      "Epoch 287/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1825 - val_loss: 0.2646\n",
      "Epoch 288/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1828 - val_loss: 0.2548\n",
      "Epoch 289/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1819 - val_loss: 0.2580\n",
      "Epoch 290/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1834 - val_loss: 0.2607\n",
      "Epoch 291/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1811 - val_loss: 0.2562\n",
      "Epoch 292/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1823 - val_loss: 0.2552\n",
      "Epoch 293/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1816 - val_loss: 0.2569\n",
      "Epoch 294/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1813 - val_loss: 0.2535\n",
      "Epoch 295/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1817 - val_loss: 0.2578\n",
      "Epoch 296/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1816 - val_loss: 0.2692\n",
      "Epoch 297/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1849 - val_loss: 0.2652\n",
      "Epoch 298/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1856 - val_loss: 0.2664\n",
      "Epoch 299/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1830 - val_loss: 0.2555\n",
      "Epoch 300/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1783 - val_loss: 0.2605\n",
      "Epoch 301/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1792 - val_loss: 0.2665\n",
      "Epoch 302/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1880 - val_loss: 0.2537\n",
      "Epoch 303/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1793 - val_loss: 0.2625\n",
      "Epoch 304/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1785 - val_loss: 0.2546\n",
      "Epoch 305/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1800 - val_loss: 0.2536\n",
      "Epoch 306/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1796 - val_loss: 0.2610\n",
      "Epoch 307/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1785 - val_loss: 0.2599\n",
      "Epoch 308/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1889 - val_loss: 0.2603\n",
      "Epoch 309/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1795 - val_loss: 0.2540\n",
      "Epoch 310/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1777 - val_loss: 0.2566\n",
      "Epoch 311/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1804 - val_loss: 0.2602\n",
      "Epoch 312/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1788 - val_loss: 0.2573\n",
      "Epoch 313/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1815 - val_loss: 0.2589\n",
      "Epoch 314/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1937 - val_loss: 0.2559\n",
      "Epoch 315/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1780 - val_loss: 0.2584\n",
      "Epoch 316/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1775 - val_loss: 0.2559\n",
      "Epoch 317/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1779 - val_loss: 0.2572\n",
      "Epoch 318/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1775 - val_loss: 0.2607\n",
      "Epoch 319/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1771 - val_loss: 0.2574\n",
      "Epoch 320/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1767 - val_loss: 0.2580\n",
      "Epoch 321/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1779 - val_loss: 0.2580\n",
      "Epoch 322/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1781 - val_loss: 0.2616\n",
      "Epoch 323/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1819 - val_loss: 0.2595\n",
      "Epoch 324/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1788 - val_loss: 0.2694\n",
      "Epoch 325/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1782 - val_loss: 0.2591\n",
      "Epoch 326/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1785 - val_loss: 0.2656\n",
      "Epoch 327/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1780 - val_loss: 0.2690\n",
      "Epoch 328/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1784 - val_loss: 0.2689\n",
      "Epoch 329/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1831 - val_loss: 0.2588\n",
      "Epoch 330/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1801 - val_loss: 0.2569\n",
      "Epoch 331/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1797 - val_loss: 0.2616\n",
      "Epoch 332/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1774 - val_loss: 0.2591\n",
      "Epoch 333/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1772 - val_loss: 0.2585\n",
      "Epoch 334/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1797 - val_loss: 0.2632\n",
      "Epoch 335/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1816 - val_loss: 0.2617\n",
      "Epoch 336/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1788 - val_loss: 0.2621\n",
      "Epoch 337/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1777 - val_loss: 0.2587\n",
      "Epoch 338/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1780 - val_loss: 0.2591\n",
      "Epoch 339/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1757 - val_loss: 0.2767\n",
      "Epoch 340/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1769 - val_loss: 0.2599\n",
      "Epoch 341/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1796 - val_loss: 0.2591\n",
      "Epoch 342/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1756 - val_loss: 0.2639\n",
      "Epoch 343/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1784 - val_loss: 0.2658\n",
      "Epoch 344/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1801 - val_loss: 0.2661\n",
      "Epoch 345/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1773 - val_loss: 0.2645\n",
      "Epoch 346/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1780 - val_loss: 0.2600\n",
      "Epoch 347/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1753 - val_loss: 0.2623\n",
      "Epoch 348/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1767 - val_loss: 0.2645\n",
      "Epoch 349/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1772 - val_loss: 0.2643\n",
      "Epoch 350/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1762 - val_loss: 0.2688\n",
      "Epoch 351/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1785 - val_loss: 0.2658\n",
      "Epoch 352/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1780 - val_loss: 0.2601\n",
      "Epoch 353/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1755 - val_loss: 0.2645\n",
      "Epoch 354/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1809 - val_loss: 0.2734\n",
      "Epoch 355/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1804 - val_loss: 0.2672\n",
      "Epoch 356/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1756 - val_loss: 0.2581\n",
      "Epoch 357/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1742 - val_loss: 0.2639\n",
      "Epoch 358/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1749 - val_loss: 0.2644\n",
      "Epoch 359/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1842 - val_loss: 0.2597\n",
      "Epoch 360/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1755 - val_loss: 0.2678\n",
      "Epoch 361/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1744 - val_loss: 0.2621\n",
      "Epoch 362/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1769 - val_loss: 0.2658\n",
      "Epoch 363/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1764 - val_loss: 0.2628\n",
      "Epoch 364/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1759 - val_loss: 0.2580\n",
      "Epoch 365/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1744 - val_loss: 0.2626\n",
      "Epoch 366/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1814 - val_loss: 0.2764\n",
      "Epoch 367/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1752 - val_loss: 0.2599\n",
      "Epoch 368/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1729 - val_loss: 0.2620\n",
      "Epoch 369/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1733 - val_loss: 0.2755\n",
      "Epoch 370/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1767 - val_loss: 0.2622\n",
      "Epoch 371/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1747 - val_loss: 0.2658\n",
      "Epoch 372/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1730 - val_loss: 0.2664\n",
      "Epoch 373/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1741 - val_loss: 0.2681\n",
      "Epoch 374/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1755 - val_loss: 0.2646\n",
      "Epoch 375/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1749 - val_loss: 0.2628\n",
      "Epoch 376/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1742 - val_loss: 0.2624\n",
      "Epoch 377/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1749 - val_loss: 0.2689\n",
      "Epoch 378/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1772 - val_loss: 0.2783\n",
      "Epoch 379/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1890 - val_loss: 0.2748\n",
      "Epoch 380/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1800 - val_loss: 0.2613\n",
      "Epoch 381/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1722 - val_loss: 0.2676\n",
      "Epoch 382/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1745 - val_loss: 0.2649\n",
      "Epoch 383/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1719 - val_loss: 0.2617\n",
      "Epoch 384/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1716 - val_loss: 0.2660\n",
      "Epoch 385/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1726 - val_loss: 0.2603\n",
      "Epoch 386/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1761 - val_loss: 0.2614\n",
      "Epoch 387/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1727 - val_loss: 0.2673\n",
      "Epoch 388/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1742 - val_loss: 0.2656\n",
      "Epoch 389/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1825 - val_loss: 0.2681\n",
      "Epoch 390/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1753 - val_loss: 0.2620\n",
      "Epoch 391/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1714 - val_loss: 0.2672\n",
      "Epoch 392/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1732 - val_loss: 0.2673\n",
      "Epoch 393/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1735 - val_loss: 0.2642\n",
      "Epoch 394/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1741 - val_loss: 0.2594\n",
      "Epoch 395/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1722 - val_loss: 0.2731\n",
      "Epoch 396/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1806 - val_loss: 0.2645\n",
      "Epoch 397/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1737 - val_loss: 0.2615\n",
      "Epoch 398/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1714 - val_loss: 0.2653\n",
      "Epoch 399/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1741 - val_loss: 0.2622\n",
      "Epoch 400/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1725 - val_loss: 0.2675\n",
      "Epoch 401/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1713 - val_loss: 0.2665\n",
      "Epoch 402/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1735 - val_loss: 0.2680\n",
      "Epoch 403/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1799 - val_loss: 0.2719\n",
      "Epoch 404/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1865 - val_loss: 0.2618\n",
      "Epoch 405/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1717 - val_loss: 0.2634\n",
      "Epoch 406/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1700 - val_loss: 0.2640\n",
      "Epoch 407/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1707 - val_loss: 0.2641\n",
      "Epoch 408/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1711 - val_loss: 0.2680\n",
      "Epoch 409/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1716 - val_loss: 0.2643\n",
      "Epoch 410/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1721 - val_loss: 0.2632\n",
      "Epoch 411/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1748 - val_loss: 0.2764\n",
      "Epoch 412/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1737 - val_loss: 0.2711\n",
      "Epoch 413/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1710 - val_loss: 0.2681\n",
      "Epoch 414/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1714 - val_loss: 0.2646\n",
      "Epoch 415/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1781 - val_loss: 0.2818\n",
      "Epoch 416/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1771 - val_loss: 0.2680\n",
      "Epoch 417/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1727 - val_loss: 0.2663\n",
      "Epoch 418/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1701 - val_loss: 0.2684\n",
      "Epoch 419/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1717 - val_loss: 0.2812\n",
      "Epoch 420/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1797 - val_loss: 0.2683\n",
      "Epoch 421/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1701 - val_loss: 0.2655\n",
      "Epoch 422/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1697 - val_loss: 0.2620\n",
      "Epoch 423/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1692 - val_loss: 0.2739\n",
      "Epoch 424/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1702 - val_loss: 0.2720\n",
      "Epoch 425/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1752 - val_loss: 0.2766\n",
      "Epoch 426/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1800 - val_loss: 0.2650\n",
      "Epoch 427/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1755 - val_loss: 0.2627\n",
      "Epoch 428/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1689 - val_loss: 0.2690\n",
      "Epoch 429/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1685 - val_loss: 0.2684\n",
      "Epoch 430/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1694 - val_loss: 0.2735\n",
      "Epoch 431/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1700 - val_loss: 0.2733\n",
      "Epoch 432/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1726 - val_loss: 0.2682\n",
      "Epoch 433/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1722 - val_loss: 0.2701\n",
      "Epoch 434/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1704 - val_loss: 0.2702\n",
      "Epoch 435/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1698 - val_loss: 0.2704\n",
      "Epoch 436/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1726 - val_loss: 0.2693\n",
      "Epoch 437/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1794 - val_loss: 0.2711\n",
      "Epoch 438/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1741 - val_loss: 0.2680\n",
      "Epoch 439/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1704 - val_loss: 0.2655\n",
      "Epoch 440/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1705 - val_loss: 0.2672\n",
      "Epoch 441/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1755 - val_loss: 0.2727\n",
      "Epoch 442/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1701 - val_loss: 0.2666\n",
      "Epoch 443/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1693 - val_loss: 0.2712\n",
      "Epoch 444/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1700 - val_loss: 0.2739\n",
      "Epoch 445/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1698 - val_loss: 0.2693\n",
      "Epoch 446/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1719 - val_loss: 0.2748\n",
      "Epoch 447/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1713 - val_loss: 0.2728\n",
      "Epoch 448/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1693 - val_loss: 0.2693\n",
      "Epoch 449/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1683 - val_loss: 0.2741\n",
      "Epoch 450/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1696 - val_loss: 0.2710\n",
      "Epoch 451/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1707 - val_loss: 0.2722\n",
      "Epoch 452/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1780 - val_loss: 0.2721\n",
      "Epoch 453/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1693 - val_loss: 0.2719\n",
      "Epoch 454/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1703 - val_loss: 0.2749\n",
      "Epoch 455/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1696 - val_loss: 0.2744\n",
      "Epoch 456/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1707 - val_loss: 0.2884\n",
      "Epoch 457/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1792 - val_loss: 0.2741\n",
      "Epoch 458/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1688 - val_loss: 0.2678\n",
      "Epoch 459/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1668 - val_loss: 0.2690\n",
      "Epoch 460/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1684 - val_loss: 0.2687\n",
      "Epoch 461/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1682 - val_loss: 0.2708\n",
      "Epoch 462/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1693 - val_loss: 0.2725\n",
      "Epoch 463/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1702 - val_loss: 0.2771\n",
      "Epoch 464/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1741 - val_loss: 0.2691\n",
      "Epoch 465/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1670 - val_loss: 0.2695\n",
      "Epoch 466/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1701 - val_loss: 0.2902\n",
      "Epoch 467/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1808 - val_loss: 0.2718\n",
      "Epoch 468/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1688 - val_loss: 0.2753\n",
      "Epoch 469/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1669 - val_loss: 0.2756\n",
      "Epoch 470/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1674 - val_loss: 0.2744\n",
      "Epoch 471/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1684 - val_loss: 0.2751\n",
      "Epoch 472/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1686 - val_loss: 0.2723\n",
      "Epoch 473/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1672 - val_loss: 0.2696\n",
      "Epoch 474/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1722 - val_loss: 0.2705\n",
      "Epoch 475/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1676 - val_loss: 0.2747\n",
      "Epoch 476/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1694 - val_loss: 0.2722\n",
      "Epoch 477/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1694 - val_loss: 0.2888\n",
      "Epoch 478/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1824 - val_loss: 0.2672\n",
      "Epoch 479/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1661 - val_loss: 0.2708\n",
      "Epoch 480/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1674 - val_loss: 0.2723\n",
      "Epoch 481/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1691 - val_loss: 0.2739\n",
      "Epoch 482/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1675 - val_loss: 0.2691\n",
      "Epoch 483/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1747 - val_loss: 0.2926\n",
      "Epoch 484/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1770 - val_loss: 0.2679\n",
      "Epoch 485/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1672 - val_loss: 0.2714\n",
      "Epoch 486/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1658 - val_loss: 0.2721\n",
      "Epoch 487/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1666 - val_loss: 0.2726\n",
      "Epoch 488/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1659 - val_loss: 0.2748\n",
      "Epoch 489/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1675 - val_loss: 0.2722\n",
      "Epoch 490/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1699 - val_loss: 0.2796\n",
      "Epoch 491/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1683 - val_loss: 0.2747\n",
      "Epoch 492/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1676 - val_loss: 0.2751\n",
      "Epoch 493/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1668 - val_loss: 0.2776\n",
      "Epoch 494/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1717 - val_loss: 0.2727\n",
      "Epoch 495/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1708 - val_loss: 0.2873\n",
      "Epoch 496/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1714 - val_loss: 0.2706\n",
      "Epoch 497/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1676 - val_loss: 0.2717\n",
      "Epoch 498/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1661 - val_loss: 0.2791\n",
      "Epoch 499/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1669 - val_loss: 0.2763\n",
      "Epoch 500/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1663 - val_loss: 0.2763\n",
      "Epoch 501/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1709 - val_loss: 0.2725\n",
      "Epoch 502/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1665 - val_loss: 0.2734\n",
      "Epoch 503/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1655 - val_loss: 0.2794\n",
      "Epoch 504/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1698 - val_loss: 0.3077\n",
      "Epoch 505/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1729 - val_loss: 0.2812\n",
      "Epoch 506/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1661 - val_loss: 0.2778\n",
      "Epoch 507/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1696 - val_loss: 0.2763\n",
      "Epoch 508/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1674 - val_loss: 0.2725\n",
      "Epoch 509/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1659 - val_loss: 0.2729\n",
      "Epoch 510/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1670 - val_loss: 0.2750\n",
      "Epoch 511/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1674 - val_loss: 0.2850\n",
      "Epoch 512/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1690 - val_loss: 0.3022\n",
      "Epoch 513/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1725 - val_loss: 0.2809\n",
      "Epoch 514/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1679 - val_loss: 0.2739\n",
      "Epoch 515/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1655 - val_loss: 0.2724\n",
      "Epoch 516/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1654 - val_loss: 0.2788\n",
      "Epoch 517/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1676 - val_loss: 0.2839\n",
      "Epoch 518/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1720 - val_loss: 0.2711\n",
      "Epoch 519/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1666 - val_loss: 0.2825\n",
      "Epoch 520/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1646 - val_loss: 0.2781\n",
      "Epoch 521/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1686 - val_loss: 0.2817\n",
      "Epoch 522/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1680 - val_loss: 0.2786\n",
      "Epoch 523/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1669 - val_loss: 0.2789\n",
      "Epoch 524/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1679 - val_loss: 0.2772\n",
      "Epoch 525/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1652 - val_loss: 0.2748\n",
      "Epoch 526/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1643 - val_loss: 0.2815\n",
      "Epoch 527/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1640 - val_loss: 0.2776\n",
      "Epoch 528/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1712 - val_loss: 0.2793\n",
      "Epoch 529/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1745 - val_loss: 0.2777\n",
      "Epoch 530/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1648 - val_loss: 0.2775\n",
      "Epoch 531/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1644 - val_loss: 0.2839\n",
      "Epoch 532/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1666 - val_loss: 0.2737\n",
      "Epoch 533/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1727 - val_loss: 0.2770\n",
      "Epoch 534/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1681 - val_loss: 0.2777\n",
      "Epoch 535/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1667 - val_loss: 0.2770\n",
      "Epoch 536/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1648 - val_loss: 0.2759\n",
      "Epoch 537/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1630 - val_loss: 0.2735\n",
      "Epoch 538/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1638 - val_loss: 0.2802\n",
      "Epoch 539/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1667 - val_loss: 0.2789\n",
      "Epoch 540/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1651 - val_loss: 0.2766\n",
      "Epoch 541/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1667 - val_loss: 0.2781\n",
      "Epoch 542/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1648 - val_loss: 0.2756\n",
      "Epoch 543/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1796 - val_loss: 0.3353\n",
      "Epoch 544/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1725 - val_loss: 0.2768\n",
      "Epoch 545/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1636 - val_loss: 0.2755\n",
      "Epoch 546/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1626 - val_loss: 0.2746\n",
      "Epoch 547/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1635 - val_loss: 0.2803\n",
      "Epoch 548/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1651 - val_loss: 0.2807\n",
      "Epoch 549/2000\n",
      "15000/15000 [==============================] - 1s 72us/step - loss: 0.1678 - val_loss: 0.2821\n",
      "Epoch 550/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1643 - val_loss: 0.2767\n",
      "Epoch 551/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1648 - val_loss: 0.2791\n",
      "Epoch 552/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1664 - val_loss: 0.2989\n",
      "Epoch 553/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1711 - val_loss: 0.2787\n",
      "Epoch 554/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1685 - val_loss: 0.2786\n",
      "Epoch 555/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1625 - val_loss: 0.2785\n",
      "Epoch 556/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1640 - val_loss: 0.2771\n",
      "Epoch 557/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1650 - val_loss: 0.2811\n",
      "Epoch 558/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1736 - val_loss: 0.2907\n",
      "Epoch 559/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1684 - val_loss: 0.2863\n",
      "Epoch 560/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1648 - val_loss: 0.2766\n",
      "Epoch 561/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1617 - val_loss: 0.2786\n",
      "Epoch 562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1633 - val_loss: 0.2780\n",
      "Epoch 563/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1648 - val_loss: 0.2875\n",
      "Epoch 564/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1679 - val_loss: 0.2795\n",
      "Epoch 565/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1662 - val_loss: 0.2901\n",
      "Epoch 566/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1688 - val_loss: 0.2793\n",
      "Epoch 567/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1641 - val_loss: 0.2811\n",
      "Epoch 568/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1656 - val_loss: 0.2810\n",
      "Epoch 569/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1629 - val_loss: 0.2862\n",
      "Epoch 570/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1632 - val_loss: 0.2782\n",
      "Epoch 571/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1627 - val_loss: 0.2798\n",
      "Epoch 572/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1706 - val_loss: 0.2880\n",
      "Epoch 573/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1657 - val_loss: 0.2781\n",
      "Epoch 574/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1625 - val_loss: 0.2805\n",
      "Epoch 575/2000\n",
      "15000/15000 [==============================] - 1s 66us/step - loss: 0.1687 - val_loss: 0.2874\n",
      "Epoch 576/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1685 - val_loss: 0.2811\n",
      "Epoch 577/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1644 - val_loss: 0.2814\n",
      "Epoch 578/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1620 - val_loss: 0.2803\n",
      "Epoch 579/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1651 - val_loss: 0.2768\n",
      "Epoch 580/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1647 - val_loss: 0.3026\n",
      "Epoch 581/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1686 - val_loss: 0.2907\n",
      "Epoch 582/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1666 - val_loss: 0.2818\n",
      "Epoch 583/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1649 - val_loss: 0.2856\n",
      "Epoch 584/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1630 - val_loss: 0.2802\n",
      "Epoch 585/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1619 - val_loss: 0.2801\n",
      "Epoch 586/2000\n",
      "15000/15000 [==============================] - 1s 67us/step - loss: 0.1643 - val_loss: 0.2908\n",
      "Epoch 587/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1644 - val_loss: 0.2902\n",
      "Epoch 588/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1689 - val_loss: 0.2892\n",
      "Epoch 589/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1635 - val_loss: 0.2809\n",
      "Epoch 590/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1637 - val_loss: 0.2820\n",
      "Epoch 591/2000\n",
      "15000/15000 [==============================] - 1s 71us/step - loss: 0.1691 - val_loss: 0.2933\n",
      "Epoch 592/2000\n",
      "15000/15000 [==============================] - 1s 70us/step - loss: 0.1642 - val_loss: 0.2794\n",
      "Epoch 593/2000\n",
      "15000/15000 [==============================] - 1s 68us/step - loss: 0.1667 - val_loss: 0.2846\n",
      "Epoch 594/2000\n",
      "15000/15000 [==============================] - 1s 69us/step - loss: 0.1680 - val_loss: 0.2788\n",
      "Epoch 595/2000\n",
      " 7808/15000 [==============>...............] - ETA: 0s - loss: 0.1612"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8d5dd2bb8def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m                 \u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestOutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;31m#                 ,verbose=1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#                 ,callbacks=[ModelCheckpoint(folder_path + \"model_{epoch:02d}_{loss:.2f}_{val_loss:.2f}.hdf5\",\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, LambdaCallback\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "encoding_sizes = [32, 16, 8, 4]\n",
    "\n",
    "for encoding in encoding_sizes:\n",
    "    input_level=layers.Input(shape=(10,10,7))\n",
    "    encoded_level=layers.Input(shape=(encoding,))\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=(1,1))(input_level)\n",
    "    x = layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((2,2), padding=\"same\")(x)\n",
    "    x = layers.Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((3,3), padding=\"same\")(x)\n",
    "    x = layers.Dense(encoding, activation=\"relu\")(x)\n",
    "    encoded = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Reshape((1,1,encoding))(encoded)\n",
    "    x = layers.Dense(32, activation=\"relu\")(x)\n",
    "    x = layers.UpSampling2D((3,3))(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2D(7, (3,3), padding=\"valid\")(x)\n",
    "    decoded = layers.Softmax(axis=3)(x)\n",
    "\n",
    "    autoencoder = Model(input_level, decoded)\n",
    "    encoder = Model(input_level, encoded)\n",
    "    decoded = autoencoder.layers[-9](encoded_level)\n",
    "    decoded = autoencoder.layers[-8](decoded)\n",
    "    decoded = autoencoder.layers[-7](decoded)\n",
    "    decoded = autoencoder.layers[-6](decoded)\n",
    "    decoded = autoencoder.layers[-5](decoded)\n",
    "    decoded = autoencoder.layers[-4](decoded)\n",
    "    decoded = autoencoder.layers[-3](decoded)\n",
    "    decoded = autoencoder.layers[-2](decoded)\n",
    "    decoded = autoencoder.layers[-1](decoded)\n",
    "    decoder = Model(encoded_level,decoded)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss=normal_loss)\n",
    "    autoencoder.summary()\n",
    "    \n",
    "#     folder_path = \"Weights/Encoding_\" + str(encoding) + \"/\"\n",
    "#     os.mkdir(folder_path)\n",
    "    \n",
    "#     log_dir=\"logs/fit/encoding_\" + str(encoding) + \"_images_\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#     writer = tf.summary.FileWriter(log_dir + \"_encoding_mag\")\n",
    "#     tensorboard_callback = TensorBoard(log_dir=log_dir)\n",
    "#     file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
    "#     file_writer.set_as_default()\n",
    "#     def recordSummary(epoch, logs):\n",
    "#         encoding_mag = K.mean(K.sqrt(K.sum(K.square(encoded), axis=1)), axis=0)\n",
    "#         tf.summary.scalar('encoding_mag', data=encoding_mag, step=epoch)\n",
    "#     summary_callback = LambdaCallback(on_train_batch_end=recordSummary)\n",
    "    \n",
    "    autoencoder.fit(trainInput, trainOutput\n",
    "                ,epochs=2000\n",
    "                ,batch_size=128\n",
    "                ,shuffle=True\n",
    "                ,validation_data=(testInput, testOutput)\n",
    "#                 ,verbose=1\n",
    "#                 ,callbacks=[ModelCheckpoint(folder_path + \"model_{epoch:02d}_{loss:.2f}_{val_loss:.2f}.hdf5\", \n",
    "#                                             save_weights_only=False, save_best_only=False, save_freq=20), \n",
    "#                             tensorboard_callback]\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import Sokoban\n",
    "import keras.layers as layers\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "encoding_sizes = [4, 8, 16, 32, 64]\n",
    "\n",
    "for encoding in encoding_sizes:\n",
    "    input_level=layers.Input(shape=(10,10,7))\n",
    "    encoded_level=layers.Input(shape=(encoding,))\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=(1,1))(input_level)\n",
    "    x = layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((4,4), padding=\"same\")(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.MaxPooling2D((3,3), padding=\"same\")(x)\n",
    "    x = layers.Dense(encoding, activation=\"sigmoid\", name='encoded')(x)\n",
    "    encoded = layers.Flatten()(x)\n",
    "\n",
    "    x = layers.Reshape((1,1,encoding))(encoded)\n",
    "    x = layers.UpSampling2D((3,3))(x)\n",
    "    x = layers.Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2D(128, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = layers.UpSampling2D((2,2))(x)\n",
    "    x = layers.Conv2D(7, (3,3), padding=\"valid\")(x)\n",
    "    decoded = layers.Softmax(axis=3)(x)\n",
    "\n",
    "    autoencoder = Model(input_level, decoded)\n",
    "    encoder = Model(input_level, encoded)\n",
    "    decoded = autoencoder.layers[-8](encoded_level)\n",
    "    decoded = autoencoder.layers[-7](decoded)\n",
    "    decoded = autoencoder.layers[-6](decoded)\n",
    "    decoded = autoencoder.layers[-5](decoded)\n",
    "    decoded = autoencoder.layers[-4](decoded)\n",
    "    decoded = autoencoder.layers[-3](decoded)\n",
    "    decoded = autoencoder.layers[-2](decoded)\n",
    "    decoded = autoencoder.layers[-1](decoded)\n",
    "    decoder = Model(encoded_level,decoded)\n",
    "\n",
    "    autoencoder.compile(optimizer='adam', loss=normal_loss)\n",
    "    autoencoder.summary()\n",
    "    \n",
    "    files = os.listdir(\"Weights/Encoding_\" + str(encoding) + \"/\")\n",
    "    for f in files:\n",
    "        if \"2000\" in f:\n",
    "            autoencoder.autoencoder.load_weights(\"Weights/Encoding_\" + str(encoding) + \"/\" + f)\n",
    "            for i in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "# .#######\n",
      "#  #######\n",
      "#*@  #####\n",
      "#  $ #####\n",
      "#  #######\n",
      "##########\n",
      "##########\n",
      "##########\n",
      "##########\n",
      "b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x00\\xa0\\x00\\x00\\x00\\xa0\\x08\\x06\\x00\\x00\\x00\\x8b\\xcfg-\\x00\\x00\\x04\\xedIDATx\\x9c\\xed\\xdd1N\\x1bM\\x18\\xc6\\xf1\\x97\\x98[`\\xd9\\x9dQh\\xe8s\\x05\\x8b\\x88;\\xb8\\x88\\xa8,\\xb9\\xe0\\x10\\x14\\x91\\xdc\\x91\"w\\xb0\\x14q\\x05zR\\x04\\x91n\\x11\\x94\\x1c\\xc1\"\\x05Z\\xc7,c\\xbc\\xcc\\x8c\\xfc\\xcc\\xec\\xfc\\x7fR\\xe4/\\x11o\\x16)\\x8f\\x1e\\xcf\\xda\\xaf\\xf9\\xf6\\x9e\\x9f\\xce\\x9e\\xcd\\xd3\\xed\\xc9\\x8d}\\xfeu\\xec;\\xce<\\xf3\\xb6_\\xff\\x87\\x8fyU\\xd9\\xa5\\x1d3\\xcf\\xbc\\xf7\\xfc\\'\\xafI \\x12\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08)\\x02\\x08\\xa9\\xfd\\xdb\\x93\\x1b\\x9bW\\x95\\xf7_\\xc0<\\xf3!\\xf3{\\xa1\\xfb\\x80\\xbd\\xd3\\x07\\xef\\x8b\\xc70\\x9a\\x8c\\xbdgS\\xd8\\x87+}>|\\x1fp\\xf2\\xd5\\xfe\\xfe\\xbc\\xf2\\xfe&F\\x93q\\xd0\\xbc\\x19\\xfb\\x8c9\\xcf\\x07\\x9f\\x01C\\xc3S\\xcf\\x1f\\x9e\\xdf{=\"o\\xc1\\x01\\x0cy\\n\\\\\\x9f\\xbf\\xbb\\x18x=\"oI4 \\xedW\\xae$\\x1a\\x90\\xf6+W\\x12\\rh\\xc6\\x19\\xb0TI4\\xa0\\x19g\\xc0R%\\xd1\\x80\\xb4_\\xb9\\x92h@\\xda\\xaf\\\\I4\\xa0\\x19g\\xc0R%\\xd1\\x80f\\x9c\\x01K\\x95D\\x03\\xd2~\\xe5J\\xa2\\x01i\\xbfr%\\xd1\\x80f\\x9c\\x01K\\x15\\xbc\\x0fXo\\xb3\\x84>>?\\x9dy=\\xaa\\xf7\\xd9\\x98g\\x1f\\xd0{6\\x85}\\xb8\\xd2\\xe7\\xd9\\x07\\xcc|\\x9f.\\xf7\\xf9d\\xce\\x80(S\\x12w\\xc1(\\x17\\r\\x08)\\x1a\\x10R4 \\xa4h@H\\xd1\\x80\\x90\\xa2\\x01!E\\x03B\\x8a\\x06\\x84\\x14\\r\\x08)\\x1a\\x10R4 \\xa4\\x92\\xd9\\x07\\xf4}T\\xef\\xb31_\\xf8>\\xa0\\x1a\\xfb\\x88\\x1d\\xde\\x07\\x1cM\\xc6\\xab\\xefmS\\xd0C\\xf7\\t\\xd9G\\xd4\\xce\\xef{M\\xaeY\\xffL\\xc7\\xdd\\xc5\\xe0U#\\xb8\\xbe\\xb1\\xa3\\xebk\\xbb\\xbb\\x18\\xac\\xbe\\xbeM\\xf8\\xda\\\\\\xdf\\x17gP\\xadhw\\xc1u\\xf8nOnV\\xbf\\\\\\xbe\\x1d\\x1c\\xac\\xbe~}\\xbei}\\xfe\\xbd3\\x06w\\xe1y\\x8br\\x17|x~\\xdf\\xba\\xb1\\xcc\\xcc\\xbe\\xcf\\x97\\xaf\\xe6C\\xaf\\xaf\\x9cG\\x98(\\r\\x18\\xf29\\xddf\\x03\\x8d&\\xe3\\xd5\\x9f\\xcd\\xab\\xca\\xe6Ue\\xd3\\xe1\\xd0\\x96\\x8b\\xbe-\\x17\\xfd\\xad\\xf3\\xa1\\xd7\\xc7nE;\\x03~\\x94\\xeb\\x0c\\xb8\\\\\\xf4\\xedv\\xf1\\xbfE\\xa7\\xc3\\xe1\\x9b\\xb9\\xe5\\xa2\\xff\\xea\\x86\\x84\\x06\\xcc[\\xb43`\\xdb\\xa7\\xdf:T\\x9b\\xce\\x80\\xbd\\xd3\\x07\\xe7\\x99o^U\\xce;a\\x1a0o\\xd1\\xce\\x80m5\\xc3\\xe5j W\\xf3\\xbdw\\xfd\\x104\\xa0\\xd6N\\xcf\\x80\\xaef[o\\xa06/j7\\xbf\\x86\\x06\\xcc\\x9b\\xec\\xbd\\xe0\\xba5]\\xf3\\x1fyu\\x9d\\x06\\xcc\\xdb\\xce\\xb6a\\x9a\\xed\\xf7\\xde\\xeb\\x80\\x1fye\\x9d\\x06\\xcc[\\x94\\xbb\\xe0\\x97;Zs\\xbeL\\xe2z\\xda\\xfd\\xf1\\xf8h3\\x1b\\xac\\xe6]\\x9as/\\xe7\\xc2\\xb7O\\xd14`\\xde\\x82\\x038\\x9a\\x8c\\xed\\xce^\\xfe\\x11{\\xa7\\x0f\\xb6\\\\\\xf4\\xdf}\\xe7b6\\xed\\xad\\xc2W\\xcfo\\xba\\x11\\xa9\\xcf{\\xae`o\\x9bo+\\xc6{\\xc1\\xf0\\x17\\xed\\x0cX\\x9f\\xe9\\x8e\\xae\\xafm6\\xed\\xbd\\xb4\\x9c\\xe3\\xb1\\xf9\\xf3\\xfd\\xda6\\xe0\\xa6P\\xd3\\x80y\\x8b\\xb6\\x0f\\xe8\\xfb\\xf3\\xfd\\x9c{~v\\xb5\\xda\\xb2q\\xfe>\\xa1G\\xf5>]\\xee\\xf3\\xec\\x03\\x06b\\x1f\\xb0\\xc3\\xfb\\x809\\xcc\\x9b\\xb1\\x0f\\x98\\xc4>`*\\xf3\\xdb\\xf6\\x11\\x9b\\x8d\\xcd\\x19P+\\xfbO\\xc5\\xad\\xcf\\xb7\\xd9G\\\\_\\x05\\x8bq}\\x84\\xc9\\xfeSq\\xf5\\xbcj\\x1f\\x11a:\\xd5\\x80\\x8ay\\x84\\xe9L\\x03\\xaa\\xe6\\x11\\xa63\\r\\xf8\\xd1}\\xc4X\\xd7G\\x98\\xe2\\x1a\\xb0\\xcd>\"v\\xa73\\r\\xd8\\xc6\\xb6}D\\xec^q\\r\\x18{\\x1ea\\x8ai\\xc0M\\xefW\\xd2\\x80Z\\x9dy\\'\\xa4^\\x05kr\\x05o6\\xedE\\xbb>\\xc2t\\xaa\\x01\\xeb\\xb7\\xd9\\xea\\xcf\\x13o\\x0b_\\x8c\\xeb#Lg\\x1a\\xb0\\xd6;}\\xb0\\x99\\xf56|u\\xfc\\xeb#\\xcc\\xde\\x9f/_\\x9eC\\xf6\\xb9.\\x7f\\xa7\\xb9\\xa7\\xb7\\xab\\xc7m\\x1b\\xe0\\xdbL\\x87\\xc3\\xa2\\xe7\\xb3\\xdf\\x07d\\x1f/\\xef\\xf9\\xec\\xf7\\x01\\xcd\\xd8\\xc7\\xcby>\\xfb\\xd7\\x01\\x91\\xb7\\xec\\xef\\x82\\x917\\x1a\\x10R4 \\xa4h@H\\xd1\\x80\\x90\\xa2\\x01!E\\x03B\\x8a\\x06\\x84\\x14\\r\\x08)\\x1a\\x10R4 \\xa4h@H\\xf1\\xff\\x0bf>\\xef\\x9f\\x0f\\xa8\\xde\\'c>\\xef\\xf9\\xf0}\\xc0\\xcc\\xf7\\xd1\\x98\\xcf|\\x1f\\x10\\x08A\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!E\\x00!\\x15\\xbc\\x0f\\xc8<\\xf3\\xec\\x032\\x9f\\xed<\\xfb\\x80\\xcc\\xb3\\x0f\\x88r\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\x11@H\\xb1\\x0f\\xc8<\\xfb\\x80\\xcc\\x97;\\xcf> \\xf3\\xec\\x03\\xa2\\\\\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\x04\\x10R\\xec\\x032\\xcf> \\xf3\\xe5\\xce\\xb3\\x0f\\xc8<\\xfb\\x80(\\x17\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\x01\\x84\\x14\\xfb\\x80\\xccK\\xe7\\xff\\x01p\\x1a&B!\\x86\\x7f4\\x00\\x00\\x00\\x00IEND\\xaeB`\\x82'\n",
      "BFS: True 33 450\n",
      "0.008102788000542205\n",
      "HeapQ AStar 1.0: True 33 418\n",
      "0.020268631000362802\n",
      "HeapQ AStar 0.0: True 33 302\n",
      "0.016013224001653725\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import Sokoban\n",
    "import imp\n",
    "imp.reload(Sokoban)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "stringLvl=numpyToString(normalData[0])\n",
    "print(stringLvl)\n",
    "state=Sokoban.State()\n",
    "state.stringInitialize(stringLvl.split(\"\\n\"))\n",
    "aStarAgent = Sokoban.AStarAgent()\n",
    "enaStarAgent = Sokoban.EnhancedAStarAgent()\n",
    "bfsAgent = Sokoban.BFSAgent()\n",
    "dfsAgent = Sokoban.DFSAgent()\n",
    "\n",
    "image = state.getImage()\n",
    "import io\n",
    "output = io.BytesIO()\n",
    "image.save(output, format='PNG')\n",
    "image_string = output.getvalue()\n",
    "output.close()\n",
    "\n",
    "start = time.process_time()\n",
    "sol,solState,iters = bfsAgent.getSolution(state, 500000)\n",
    "print(\"BFS: \" + str(solState.checkWin()) + \" \" + str(len(sol)) + \" \" + str(iters))\n",
    "print(time.process_time() - start)\n",
    "\n",
    "start = time.process_time()\n",
    "sol,solState,iters = enaStarAgent.getSolution(state, 1, 100000)\n",
    "print(\"HeapQ AStar 1.0: \" + str(solState.checkWin()) + \" \" + str(len(sol)) + \" \" + str(iters))\n",
    "print(time.process_time() - start)\n",
    "\n",
    "# start = time.process_time()\n",
    "# sol,solState,iters = enaStarAgent.getSolution(state, 0.5, 100000)\n",
    "# print(\"HeapQ AStar 0.5: \" + str(solState.checkWin()) + \" \" + str(len(sol)) + \" \" + str(iters))\n",
    "# print(time.process_time() - start)\n",
    "\n",
    "# start = time.process_time()\n",
    "# sol,solState,iters = enaStarAgent.getSolution(state, 0.25, 100000)\n",
    "# print(\"HeapQ AStar 0.25: \" + str(solState.checkWin()) + \" \" + str(len(sol)) + \" \" + str(iters))\n",
    "# print(time.process_time() - start)\n",
    "\n",
    "start = time.process_time()\n",
    "sol,solState,iters = enaStarAgent.getSolution(state, 0, 100000)\n",
    "print(\"HeapQ AStar 0.0: \" + str(solState.checkWin()) + \" \" + str(len(sol)) + \" \" + str(iters))\n",
    "print(time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensorboard.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
