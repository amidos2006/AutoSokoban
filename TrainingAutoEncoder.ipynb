{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Reshape, Softmax\n",
    "from keras.models import Model\n",
    "\n",
    "encoding=16\n",
    "\n",
    "input_level=Input(shape=(10,10,7))\n",
    "encoded_level=Input(shape=(encoding,))\n",
    "\n",
    "x = Conv2D(64, (3,3), activation=\"relu\", padding=\"same\")(input_level)\n",
    "x = MaxPooling2D((2,2), padding=\"same\")(x)\n",
    "x = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = MaxPooling2D((4,4), padding=\"valid\")(x)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = Dense(encoding, activation=\"sigmoid\")(x)\n",
    "encoded = Flatten()(x)\n",
    "\n",
    "x = Reshape((1,1,16))(encoded)\n",
    "x = Dense(32, activation=\"relu\")(x)\n",
    "x = UpSampling2D((4,4))(x)\n",
    "x = Conv2D(32, (3,3), activation=\"relu\", padding=\"same\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(64, (3,3), activation=\"relu\", padding=\"valid\")(x)\n",
    "x = UpSampling2D((2,2))(x)\n",
    "x = Conv2D(7, (3,3), padding=\"valid\")(x)\n",
    "decoded = Softmax(axis=3)(x)\n",
    "\n",
    "autoencoder = Model(input_level, decoded)\n",
    "encoder = Model(input_level, encoded)\n",
    "decoded = autoencoder.layers[-9](encoded_level)\n",
    "decoded = autoencoder.layers[-8](decoded)\n",
    "decoded = autoencoder.layers[-7](decoded)\n",
    "decoded = autoencoder.layers[-6](decoded)\n",
    "decoded = autoencoder.layers[-5](decoded)\n",
    "decoded = autoencoder.layers[-4](decoded)\n",
    "decoded = autoencoder.layers[-3](decoded)\n",
    "decoded = autoencoder.layers[-2](decoded)\n",
    "decoded = autoencoder.layers[-1](decoded)\n",
    "decoder = Model(encoded_level,decoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"FinalData/original_data.npz\")\n",
    "inputData,outputData=data[\"input\"],data[\"output\"]\n",
    "np.random.shuffle(inputData)\n",
    "np.random.shuffle(outputData)\n",
    "trainInput,trainOutput=inputData[0:15000],outputData[0:15000]\n",
    "testInput,testOutput=inputData[15000:],outputData[15000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def numpyToString(array):\n",
    "    gameCharacters=\"# @$.+*\"\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(gameCharacters))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(gameCharacters))\n",
    "    intArray = np.argmax(array, axis=2)\n",
    "    output=\"\"\n",
    "    for (i,j), index in np.ndenumerate(intArray):\n",
    "        if i > 0 and j == 0:\n",
    "            output += \"\\n\"\n",
    "        output += int_to_char[index]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
